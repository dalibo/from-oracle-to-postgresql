"use strict";(function(){const t={cache:!0};t.doc={id:"id",field:["title","content"],store:["title","href","section"]};const e=FlexSearch.create("balance",t);window.bookSearchIndex=e,e.add({id:0,href:"/from-oracle-to-postgresql/datatypes/",title:"Datatypes",section:"Porting database objects",content:` Datatypes # The Oracle RDBMS does not support every SQL standard data type natively. Some are supported but converted into an equivalent internal type. For example, all native integer types, like integer being converted to NUMBER(38). Also, the VARCHAR2 type is specific to Oracle and differs from the standard on its way to handle the NULL value. Additionally, many Oracle specific data types are named differently in PostgreSQL.
type Oracle type PostgreSQL varchar2, nchar2, nvarchar2, nclob varchar, text clob, long varchar, text blob, raw, long raw bytea number numeric, integer, bigint, smallint, real, double precision date date, timestamp binary float real binary double double precision Boolean type # Oracle does not handle a proper boolean type. Depending on the application developper, a CHAR or a NUMBER type is used to emulate the behavior. Ora2Pg can handle the transformation of a boolean value to PostgreSQL.
Also, note that the lack of boolean value in Oracle can result in some pains with ORM like Hibernate if the datatypes are not ported correctly. The column seen configured as a boolean on the ORM side will be stored as a NUMBER or CHAR type on the Oracle side. If no care has been taken to transform the boolean type and values accordingly, the ORM will look for a boolean value in PostgreSQL and will find something different, resulting in an error. More generally, when using ORM, it is better to start from a database schema generated by the application and convert the data accordingly.
SELECT true AND false; -- -[ RECORD 1 ] -- ?column? | f SELECT true OR false; -- -[ RECORD 1 ] -- ?column? | t Character types # Oracle implements a specific datatype, VARCHAR2. This type does not handle an empty string and NULL according the SQL standard, as an empty string and a NULL are both seen as a NULL value. Thus, in Oracle, when you compare a value with '', this is equivalent to IS NULL.
On the contrary, PostgreSQL provides an SQL standard conformant varchar datatype: comparing to '' is something distinct from IS NULL.
There is another subtle difference regarding length limit, but it usually is not a problem during porting. While Oracle\u0026rsquo;s length limit is by default expressed in bytes (it can be changed with NLS_LENGTH_SEMANTICS), PostgreSQL length limit is expressed in characters. Moreover, in PostgreSQL, one can use a varchar datatype without providing a limit, which is equivalent to PostgreSQL\u0026rsquo;s text datatype. In this case, the string will be limited to 1GB.
While porting applications, another subtle differences can appear while comparing char and varchar datas. This is not clearly described in the SQL standard and each RDBMS has its own interpretation: while comparing thoses types, PostgreSQL converts each data from varchar to char. Some empty spaces (padding) will be added on the right of varchar string, in order to obtain the same length as char(x).
For example:
SELECT \u0026#39;foo\u0026#39;::CHAR(5)=\u0026#39;foo \u0026#39;::VARCHAR(5); -- ?column? -- ---------- -- t SELECT \u0026#39;foo \u0026#39;::CHAR(5)=\u0026#39;foo\u0026#39;::VARCHAR(5); -- ?column? -- ---------- -- t SELECT \u0026#39;foo \u0026#39;::VARCHAR(5)=\u0026#39;foo\u0026#39;::VARCHAR(5); -- ?column? -- ---------- -- f This feature can have undesirable effects on execution plans:
CREATE TABLE t1 (a VARCHAR(5)); INSERT INTO t1 SELECT generate_series(1,10000); CREATE INDEX idx1 ON t1(a); EXPLAIN SELECT * FROM t1 WHERE a=\u0026#39;foo\u0026#39;::CHAR(5); -- QUERY PLAN -- ---------------------------------------------------- -- Seq Scan on t1 (cost=0.00..170.00 rows=1 width=4) -- Filter: ((a)::bpchar = \u0026#39;foo \u0026#39;::character(5)) This query can\u0026rsquo;t take advantage of the index on column a: each value must be converted to char (in fact to bpchar, which is the internal type for char) before being compared to the right argument.
This problem appears frequently when the query is embedded into a function, and when the function parameters are of type char(x). For example, the following function can be problematic:
CREATE OR REPLACE FUNCTION public.demo_char(p1 CHARACTER) RETURNS CHARACTER VARYING LANGUAGE plpgsql AS $function$ DECLARE v1 VARCHAR; BEGIN SELECT INTO v1 a FROM t1 WHERE a=p1; RETURN v1; END $function$ In this function, the SELECT statement will always do a sequential scan of table t1 because of the implicit casting issue.
References:
Character Types Character encoding and collation # In PostgreSQL, Server-side encoding is set at the database-level. A session variable named client_encoding can define the encoding at the client-level. Its default value is set accordingly to the database encoding, but can be redefined dynamically at session start with SET, for example: SET client_encoding = UTF8.
Regarding collation handling, some improvements were made since PostgreSQL 8.4:
collation global to the database cluster before release 8.4; collation per database since release 8.4; collation per column/index/SQL query since release 9.1. References:
Collation Support Temporal types # Oracle supports several datatypes to manipulate temporal data:
DATE, encodes both date and time, with a resolution of a second; TIMESTAMP, encodes date and time but with a better resolution than what PostgreSQL can handle (nanosecond); TIMESTAMP WITH TIME ZONE, same as above, with information about the time zone; INTERVAL, can have 2 resolutions: year/month or days/seconds. PostgreSQL, on the other side, implements the following datatypes:
date, encodes a date, conforming to the SQL standard; timestamp, encodes date and time, with a resolution up to 1 microsecond; time, encodes time only, with a resolution up to 1 microsecond; interval which offers a resolution up to 1 microsecond; time and timestamp can optionally hold time zone information by adding with time zone keywords, like in Oracle. The problem when porting data typed as DATE in Oracle resides in knowning if it holds only the date part or it also holds the time part.
SELECT (\u0026#39;1970-01-01\u0026#39;::DATE + \u0026#39;15 YEARS 3 MONTHS 2 DAYS 1 HOUR 23 MINUTES\u0026#39;::INTERVAL) AS calc_interval; -- -[ RECORD 1 ]-+-------------------- -- calc_interval | 1985-04-03 01:23:00 References:
Date/Time Types Composite types # All of the types that can be defined by a user are supported, but may require some adaptation. One could need to define input/output functions for these types, to manage selects and inserts on this peculiar data type. In most cases, the types are composite or array types that are completely supported by PostgreSQL.
The following composite type for Oracle:
CREATE OR REPLACE TYPE phone_t AS OBJECT ( a_code CHAR(3), p_number CHAR(8) ); and the same for PostgreSQL:
CREATE TYPE phone_t AS ( a_code CHAR(3), p_number CHAR(8) ); The following example using an array:
CREATE OR REPLACE TYPE phonelist AS VARRAY(50) OF phone_t; will be translated to:
CREATE TYPE phonelist AS (phonelist phone_t[50]); `}),e.add({id:1,href:"/from-oracle-to-postgresql/general-differences-between-oracle-and-postgresql/",title:"General differences",section:"Docs",content:` General differences between Oracle and PostgreSQL # This part is about specificities and general differences that have to be taken into account while migrating from Oracle to PostgreSQL.
Users and schemas # In Oracle Database users and schemas are two closely related objects. A user has its own schema, the schema is named after the user\u0026rsquo;s name. PostgreSQL does clearly distinguish users and schema objects. In PostgreSQL, a schema is really a real namespace for the database objects.
Case sensibility # Oracle implicitly converts objects name into uppercase while PostgreSQL converts them into lowercase. The SQL standard do not make any recommendation on this subject.
If needed, the case can be forced by using englobing the object name with double-quotes. This practice is not recommended with PostgreSQL, because each access to a particular object will each-time require double-quotes:
CREATE TABLE \u0026#34;MyTable\u0026#34; (a INTEGER PRIMARY KEY, b INTEGER); -- NOTICE: CREATE TABLE / PRIMARY KEY will CREATE -- implicit INDEX \u0026#34;MyTable_pkey\u0026#34; FOR TABLE \u0026#34;MyTable\u0026#34; -- CREATE TABLE INSERT INTO mytable (a,b) VALUES (1,1); -- ERROR: relation \u0026#34;mytable\u0026#34; does NOT exist -- LINE 1: INSERT INTO mytable (a,b) VALUES (1,1); INSERT INTO MyTable (a,b) VALUES (1,1); -- ERROR: relation \u0026#34;mytable\u0026#34; does NOT exist -- LINE 1: INSERT INTO MyTable (a,b) VALUES (1,1); INSERT INTO \u0026#34;MyTable\u0026#34; (a,b) VALUES (1,1); -- INSERT 0 1 If one forgets double-quotes in his query, PostgreSQL will implicitly convert the object name to lowercase and the query will not work correctly.
DUAL Table # The Oracle parser does not accept SELECT queries that miss the FROM clause. PostgreSQL does not have this limitation, all references to the DUAL table can be removed from the queries.
It is also counter-productive to create an artificial DUAL table on PostgreSQL. This table will need additional locks acquisition and can be a bottleneck for queries using this table.
SELECT 1+1 AS resultat; -- -[ RECORD 1 ] -- resultat | 2 NULL value # The VARCHAR2 datatype assimilates an empty string with the NULL value. This is not consistent to the SQL standard.
Several problems can appear, especially when the query developer wrote query predicates with this non-standard behavior in mind. Also, Oracle can concatenate a string with a NULL value without any problem. With PostgreSQL, and as well with other RDBMS, the NULL value is propagated in the operations: a string concatenated to a NULL will give a NULL.
SELECT \u0026#39;ABC\u0026#39;||NULL AS concatenation_with_null, coalesce(\u0026#39;ABC\u0026#39;||NULL,\u0026#39;value if null\u0026#39;,\u0026#39;value is not null\u0026#39;); -- -[ RECORD 1 ]-----------+--------------- -- concatenation_with_null | -- coalesce | value if null Database Links # PostgreSQL historically handles database links to other PostgreSQL databases through the dblink extension. However, since version 9.1, PostgreSQL features support for SQL/MED, in form of Foreign Data Wrappers (FDW). A Foreign Data Wrapper provides access to external objects in form of tabular data: another table in another database, external CSV file, etc.
An Oracle FDW exists and provides access to Oracle databases from PostgreSQL. Every new FDW features are supported, as well as spatial datas. In practice, we need to declare FOREIGN TABLEs in PostgreSQL schema, linked to remote tables. Thus, it\u0026rsquo;s easy to querying external data with SQL, in read and write access.
Foreign Data Wrapper\u0026rsquo;s implementation can collect statistics on remote tables, and transmit predicates to the driver, plus foreign tables can be updated, as long as they have a primary key. These capacities are available in Oracle\u0026rsquo;s FDW, giving access to Oracle tables in SQL.
References:
Foreign data wrappers CREATE FOREIGN TABLE `}),e.add({id:2,href:"/from-oracle-to-postgresql/porting-procedures-and-functions/",title:"Porting procedures and functions",section:"PL/SQL to PL/pgSQL porting",content:` Porting procedures and functions # Functions declaration # Both of Oracle and PostgreSQL allow functions and procedures creation, also called routines in PostgreSQL\u0026rsquo;s documentation. Procedures can be invoked by CALL word, while functions are called by SELECT or PERFORM.
Procedures with PostgreSQL do not return any result. All procedures declared with OUT parameter need to be converted to functions in PostgreSQL.
Please note, amongst the main differences:
the RETURN keyword becomes RETURNS; the IS keyword becomes AS; the body of a function is delimited by $$ (or similar) beacons; repeating the function\u0026rsquo;s name after the final END keyword is useless; local variables are put in a DECLARE block in PostgreSQL; the language has to be specified in PostgreSQL: LANGUAGE plpgsql. Below, the declaration of the cs_create_job in Oracle:
CREATE OR REPLACE PROCEDURE cs_create_job(v_job_id IN INTEGER) IS a_running_job_count INTEGER; BEGIN ... END; It will be rewritten this way in PostgreSQL:
CREATE OR REPLACE PROCEDURE cs_create_job(v_job_id INTEGER) AS $$ DECLARE a_running_job_count INTEGER; BEGIN ... END; $$ LANGUAGE plpgsql; References:
Structure of PL/pgSQL Declarations DETERMINISTIC attribute # Oracle functions declared as DETERMINISTIC will be converted to PostgreSQL functions with an IMMUTABLE attribute. IMMUTABLE and DETERMINISTIC indicate that the function doesn\u0026rsquo;t access the database, and that it will return the same result given the same parameters. This is supported by Ora2Pg.
Thus, the following declaration for Oracle:
CREATE OR REPLACE FUNCTION get_average_char(input_ VARCHAR2) RETURN VARCHAR2 DETERMINISTIC IS ... END get_average_char; becomes, for PostgreSQL:
CREATE OR REPLACE FUNCTION get_average_char(input_ VARCHAR) RETURNS VARCHAR AS $$ ... END; $$ LANGUAGE plpgsql IMMUTABLE; References:
CREATE FUNCTION PIPELINED attribute and PIPE ROW instruction # Oracle\u0026rsquo;s functions declared as PIPELINED are equivalent to Set-Returning Functions (SRF) in PosgreSQL. So, a PIPELINED function will be converted to a SETOF function. The PIPE ROW instruction will be converted to RETURN NEXT.
The following package, extracted from a PL/SQL example from Oracle uses the PIPELINED attribute and the PIPE ROW instruction:
CREATE OR REPLACE PACKAGE pkg1 AS TYPE numset_t IS TABLE OF NUMBER; FUNCTION f1(x NUMBER) RETURN numset_t PIPELINED; END pkg1; CREATE PACKAGE BODY pkg1 AS -- FUNCTION f1 RETURNS a collection of elements (1,2,3,... x) FUNCTION f1(x NUMBER) RETURN numset_t PIPELINED IS BEGIN FOR i IN 1..x LOOP PIPE ROW(i); END LOOP; RETURN; END f1; END pkg1; It will be ported quite easily by Ora2Pg:
the numset_t type isn\u0026rsquo;t converted, it will have to be modified manually after the Ora2Pg run; if the return type was %ROWTYPE in Oracle, it would have been ported to SET OF record; the pkg1 package is converted to a pkg1 schema; the f1 function is converted as follows. Here is the function, converted to PL/pgsql:
CREATE SCHEMA pkg1; CREATE OR REPLACE FUNCTION pkg1.f1 (x INTEGER) RETURNS SET OF INTEGER AS $$ DECLARE i INTEGER; BEGIN FOR i IN 1..x LOOP RETURN NEXT i; END LOOP; RETURN; END; $$ LANGUAGE plpgsql; This function will be call this way: SELECT pkg1.f1(10);.
References:
Control Structures Functions parameters # Oracle doesn\u0026rsquo;t conform completely to the SQL standard regarding to the parameters declaration of a function or a procedure. PostgreSQL, though, adheres to the standard. Minor adaptations are, a consequence, necessary for all functions declarations.
Each argument is named, has a data type, and a mode determining the behavior of the parameter In Oracle, the parameter mode is declared after its name. In PostgreSQL, the parameter mode comes before its name, as specified by the standard. The IN and OUT modes are directly transposed, IN OUT becomes INOUT. The parameter mode can be completely ignored for IN.
Thus, the following parameters declaration in Oracle:
CREATE FUNCTION test (p INTEGER) ... CREATE OR REPLACE PROCEDURE cs_parse_url( v_url IN VARCHAR, v_host IN OUT VARCHAR, v_path OUT VARCHAR, v_query OUT VARCHAR ) ... become in PostgreSQL:
CREATE FUNCTION test (p INTEGER) ... CREATE OR REPLACE FUNCTION cs_parse_url( IN v_url VARCHAR, INOUT v_host VARCHAR, OUT v_path VARCHAR, OUT v_query VARCHAR ) ... References:
SQL Functions with Output Parameters Default value for a parameter # PostgreSQL accept default values for arguments. Functions declarations using default values can be copied without modification.
For instance, a function such as this one in Oracle:
CREATE FUNCTION fonction1 (a INT, b INT, c INT := 0) ... will be rewritten this way in PostgreSQL:
CREATE FUNCTION fonction1 (a INT, b INT, c INT = 0) ... The DEFAULT keyword is valid in both languages.
References:
CREATE FUNCTION `}),e.add({id:3,href:"/from-oracle-to-postgresql/specificities-on-data-types/",title:"Specificities on Data types",section:"Porting SQL queries",content:` Specificities on Data types # Varchar handling # For Oracle, an empty string is also a NULL string. It is both. PostgreSQL makes the difference: either the string is unknown (IS NULL), either it is empty.
So some queries handling strings will behave differently between Oracle and PostgreSQL. Most often, they are the consequence of a comparison between a column and an empty string, and the concatenation with a NULL string.
Comparaison # In Oracle, if the column col is of VARCHAR2 type, both following queries will return the same result:
SELECT * FROM TABLE WHERE col = \u0026#39;\u0026#39;; SELECT * FROM TABLE WHERE col IS NULL; PostgreSQL won\u0026rsquo;t return the same result. Ora2Pg converts VARCHAR2 null columns to varchar null columns, so the first query won\u0026rsquo;t return anything.
It is therefore compulsory to rewrite this query using IS NULL or IS NOT NULL. PostgreSQL will be able to use an index for this search.
If the comparison is rewritten with a COALESCE function, and keeping the comparison to the empty string, it won\u0026rsquo;t use an index.
EXPLAIN SELECT * FROM emp2 WHERE ename IS NULL; -- QUERY PLAN -- ------------------------------------------------------------------------- -- Index Scan using emp2_ename on emp2 (cost=0.00..12.87 rows=1 width=20) -- Index Cond: (ename IS NULL) EXPLAIN SELECT * FROM emp2 WHERE COALESCE(ename) = \u0026#39;\u0026#39;; -- QUERY PLAN -- ------------------------------------------------------------- -- Seq Scan on emp2 (cost=0.00..79144.81 rows=20972 width=20) -- Filter: ((COALESCE(ename))::text = \`::text) Concatenation # Because of Oracle\u0026rsquo;s VARCHAR2 specificity, concatenation with a NULL value in a string won\u0026rsquo;t be a problem. It will be in PostgreSQL though. The SQL standard defines that for most functions, a NULL parameter will produce a NULL result (they are called STRICT functions in PostgreSQL). In the present example, a NULL value in a concatenation operation will be propagated to the result, which will be NULL too, and not the expected string.
COALESCE should be added in such portions of code:
SELECT \u0026#39;employee name: \u0026#39; || COALESCE(ename, \`) FROM emp; Date manipulation # Ouptut format # In Oracle, the NLS_DATE_FORMAT determines the output format of TO_CHAR() and TO_DATE() functions.
PostgreSQL, by default, uses the ISO-8601 format for date outputs: YYYY-MM-DD HH24:MI:SS.mmmmmm+TZ. It cat be modified with the DateStyle session parameter (by default ISO, DMY), but won\u0026rsquo;t match Oracle\u0026rsquo;s anyway.
Operation on dates # Oracle permits adding or substracting an integer to or from a date. For example:
SELECT SYSDATE + 1 FROM DUAL; will return tomorrow\u0026rsquo;s date. For PostgreSQL\u0026rsquo;s date datatype, the behaviour is the same, but it won\u0026rsquo;t be for a timestamp.
To get the same result with a timestamp (the equivalent type to Oracle\u0026rsquo;s date type) with PostgreSQL, one should use an interval:
SELECT now() + INTERVAL \u0026#39;1 DAY\u0026#39;; Similarly, substracting two timestamps from one another returns an integer corresponding to the number of days between these two days, when it returns an interval with the exact difference with PostgreSQL.
SYSDATE # Please note that the DATE datatype, in Oracle, is a TIMESTAMP WITHOUT TIME ZONE in PostgreSQL.
SELECT to_char(sysdate,\u0026#39;DD/MM/YYYY HH24:MI:SS\u0026#39;) FROM dual; -- TO_CHAR(SYSDATE,\u0026#39;DD -- ------------------- -- 11/03/2011 14:58:22 One should use localtimestamp (and not current_timestamp which returns a TIMESTAMP WITH TIME ZONE):
SELECT localtimestamp; -- timestamp -- ---------------------------- -- 2011-03-11 16:59:29.889823 Thus, any variable declared as DATE in Oracle\u0026rsquo;s PL/SQL must be declared as timestamp in PostgreSQL\u0026rsquo;s PL/pgsql.
`}),e.add({id:4,href:"/from-oracle-to-postgresql/joins/",title:"Joins",section:"Porting SQL queries",content:` Joins # Oracle supports the ISO-standard way of writing joins only since the 9i version. Previously, joins were written as stipulated by the first SQL standard, with a proprietary notation for outer joins. PostgreSQL doesn\u0026rsquo;t support this proprietary notation, but has full support for the standard compliant syntaxes (old and new).
Simple join # The following query can be kept as is:
SELECT * FROM t1, t2 WHERE t1.col1 = t2.col1 However, this syntax doesn\u0026rsquo;t allow for outer joins. It is therefore recommended to use only the new notation, which is anyway much easier to read when inner and outer joins are combined in a complex query:
SELECT * FROM t1 JOIN t2 ON (t1.col1 = t2.col1) Left and right outer joins # Oracle uses the (+) notation to describe the side of the join where NULLs are allowed. For a left join, the (+) annotation would be set on the right part of the join (and conversely for a right join). This writing isn\u0026rsquo;t supported by PostgreSQL. These must be rewritten with the standard compliant syntax: LEFT OUTER JOIN or LEFT JOIN for a left join, and RIGHT OUTER JOIN or RIGHT JOIN for a right join.
The following query, written the Oracle proprietary way with a left join:
SELECT * FROM t1, t2 WHERE t1.col1 = t2.col3 (+); has to be rewritten this way:
SELECT * FROM t1 LEFT JOIN t2 ON (t1.col1 = t2.col3); Similarly, the following query contains a right join:
SELECT * FROM t1, t2 WHERE t1.col1 (+) = t2.col3; ant must be rewritten as:
SELECT * FROM t1 RIGHT JOIN t2 ON (t1.col1 = t2.col3); Full outer join # Before Oracle 9i, a FULL OUTER JOIN had to be written with a UNION between a left and a right join. Here is an example of such a full outer join:
SELECT * FROM t1, t2 WHERE t1.col1 = t2.col3 (+) UNION ALL SELECT * FROM t1, t2 WHERE t1.col1 (+) = t2.col3 AND t1.col IS NULL This query must be rewritten, and will be much simpler:
SELECT * FROM t1 FULL OUTER JOIN t2 ON (t1.col1 = t2.col3); Mixed join syntaxes # While porting from Oracle to PostgreSQL, it could be tempting to only rewrite outer joins, and keep other joins as is, to limit the amount of work.
This should be avoided: on complex queries, accessing a large number of tables, the optimizer may have trouble calculating a good execution plan: the content of the WHERE clause may not be converted as joins.
This is controlled by the from_collapse_limit setting. It is the maximum depth where the optimizer will try to re-order joins. The default is 8, which is sufficient, most of the time. A higher value may have a huge impact on planning time of the queries.
Here is a very simplified example, where from_collapse_limit will be set to 2, so that the problem appears on a simple query:
CREATE TABLE t1(a INT, b INT); CREATE TABLE t2(b INT, c INT); CREATE TABLE t3(c INT, d INT); CREATE TABLE t4(d INT, e INT); INSERT INTO t1 SELECT generate_series(1,1000000), generate_series(1,1000000); INSERT INTO t2 SELECT generate_series(1,1000000), generate_series(1,1000000); INSERT INTO t3 SELECT generate_series(1,1000000), generate_series(1,1000000); INSERT INTO t4 SELECT generate_series(1,1000000), generate_series(1,1000000); ALTER TABLE t4 add PRIMARY KEY (a); ALTER TABLE t1 add PRIMARY KEY (a); ALTER TABLE t2 add PRIMARY KEY (b); ALTER TABLE t3 add PRIMARY KEY (c); ALTER TABLE t4 add PRIMARY KEY (d); -- Statistics are now up-to-date analyze; -- 4 tables are involved, we are constraining the optimizer\u0026#39;s possibilities set from_collapse_limit TO 2; -- Modern join EXPLAIN ANALYZE SELECT * FROM t1 JOIN t2 USING (b) JOIN t3 USING (c) LEFT JOIN t4 USING (d) WHERE t1.a between 1 AND 100; -- QUERY PLAN -- ------------------------------------------------------------------------- -- Nested Loop Left Join -- (cost=1.70..1271.91 rows=101 width=20) -- (actual time=0.113..4.607 rows=100 loops=1) -- -\u0026gt; Nested Loop -- (cost=1.27..1064.28 rows=101 width=16) -- (actual time=0.097..3.129 rows=100 loops=1) -- -\u0026gt; Nested Loop -- (cost=0.85..856.40 rows=101 width=12) -- (actual time=0.081..1.669 rows=100 loops=1) -- -\u0026gt; Index Scan using t1_pkey on t1 -- (cost=0.42..10.45 rows=101 width=8) -- (actual time=0.057..0.163 rows=100 loops=1) -- Index Cond: ((a \u0026gt;= 1) AND (a \u0026lt;= 100)) -- -\u0026gt; Index Scan using t2_pkey on t2 -- (cost=0.42..8.37 rows=1 width=8) -- (actual time=0.011..0.012 rows=1 loops=100) -- Index Cond: (b = t1.b) -- -\u0026gt; Index Scan using t3_pkey on t3 -- (cost=0.42..2.05 rows=1 width=8) -- (actual time=0.011..0.012 rows=1 loops=100) -- Index Cond: (c = t2.c) -- -\u0026gt; Index Scan using t4_pkey on t4 -- (cost=0.42..2.05 rows=1 width=8) -- (actual time=0.011..0.012 rows=1 loops=100) -- Index Cond: (t3.d = d) -- Total runtime: 4.815 ms -- Mix of modern and old style joins EXPLAIN ANALYZE SELECT * FROM t1,t2,t3 LEFT JOIN t4 USING (d) WHERE t1.b=t2.b AND t2.c=t3.c AND t1.a BETWEEN 1 AND 100; -- QUERY PLAN -- ------------------------------------------------------------------------- -- Hash Join -- (cost=31689.66..79086.67 rows=101 width=28) -- (actual time=711.708..2369.201 rows=100 loops=1) -- Hash Cond: (t3.c = t2.c) -- -\u0026gt; Hash Left Join -- (cost=30832.00..74478.00 rows=1000000 width=12) -- (actual time=711.170..2217.581 rows=1000000 loops=1) -- Hash Cond: (t3.d = t4.d) -- -\u0026gt; Seq Scan on t3 -- (cost=0.00..14425.00 rows=1000000 width=8) -- (actual time=0.007..266.867 rows=1000000 loops=1) -- -\u0026gt; Hash -- (cost=14425.00..14425.00 rows=1000000 width=8) -- (actual time=710.802..710.802 rows=1000000 loops=1) -- Buckets: 131072 Batches: 2 Memory Usage: 19548kB -- -\u0026gt; Seq Scan on t4 -- (cost=0.00..14425.00 rows=1000000 width=8) -- (actual time=0.010..297.606 rows=1000000 loops=1) -- -\u0026gt; Hash -- (cost=856.40..856.40 rows=101 width=16) -- (actual time=0.511..0.511 rows=100 loops=1) -- Buckets: 1024 Batches: 1 Memory Usage: 5kB -- -\u0026gt; Nested Loop -- (cost=0.85..856.40 rows=101 width=16) -- (actual time=0.025..0.459 rows=100 loops=1) -- -\u0026gt; Index Scan using t1_pkey on t1 -- (cost=0.42..10.45 rows=101 width=8) -- (actual time=0.017..0.046 rows=100 loops=1) -- Index Cond: ((a \u0026gt;= 1) AND (a \u0026lt;= 100)) -- -\u0026gt; Index Scan using t2_pkey on t2 -- (cost=0.42..8.37 rows=1 width=8) -- (actual time=0.003..0.003 rows=1 loops=100) -- Index Cond: (b = t1.b) -- Total runtime: 2370.090 ms With a default from_collapse_limit of 8, the problem doesn\u0026rsquo;t occur on this query. It is much easier, though, to systematically correct all queries than count the involved tables in all queries to determine if the work should be done or not. The problem will also be much harder to diagnose on a complex query, involving subqueries, for example.
Cartesian product # A cartesian product can be written this way in both Oracle and PostgreSQL:
SELECT * FROM t1, t2; However, the standard-compliant syntax is much more explicit, showing the developer really intends on doing a cross join:
SELECT * FROM t1 CROSS JOIN t2; References:
Table Expressions `}),e.add({id:5,href:"/from-oracle-to-postgresql/porting-the-database-schema-to-postgresql/",title:"Porting database objects",section:"Docs",content:` Porting the database schema to PostgreSQL # DDL compatibility # The majority of DDL commands are compatible between Oracle and PostgreSQL, expect the storage clauses. There are however some fundamental differences between each RDBMS:
Oracle does an implicit COMMIT after each DDL command; on the contrary, all DDL queries are transnational in PostgreSQL; non-blocking DDL are available in Oracle, however PostgreSQL only provides CREATE INDEX CONCURRENTLY and DROP INDEX CONCURRENTLY. Much effort is also put on PostgreSQ to require minimum locking and rewriting when doing schema changes. BEGIN; CREATE TABLE mytable (a INTEGER PRIMARY KEY, b INTEGER); -- NOTICE: CREATE TABLE / PRIMARY KEY will create implicit index \u0026#34;mytable_pkey\u0026#34; -- for TABLE \u0026#34;mytable\u0026#34; -- CREATE TABLE SELECT count(*) FROM mytable; -- -[ RECORD 1 ] -- count | 0 ROLLBACK; SELECT count(*) FROM mytable; -- ERROR: relation \u0026#34;mytable\u0026#34; does not exist -- LINE 1: SELECT count(*) FROM mytable; Constraint migration # Migrating integrity constraints is of no special difficulty.
Synonyms migration # There is no equivalent to Oracle\u0026rsquo;s synonyms in PostgreSQL.
In case of namesake, a simple way is to set up PostgreSQL\u0026rsquo;s search_path session variable, which specifies the list of schemas to be searched when an object name has no schema qualification. This can be specified for each user, for a database, or dynamically whenever wanted with the SET search_path = \u0026lt;path list\u0026gt;; statement.
Otherwise, synonyms are often replaced by views, in order to expose a table in another schema with another name, or by using a wrapper function to call an invisibile function in another schema.
References:
The Schema Search Path `}),e.add({id:6,href:"/from-oracle-to-postgresql/table-migration/",title:"Table migration",section:"Porting database objects",content:` Table migration # Table definition are quite identical between both RDBMS, except that PostgreSQL does not have global temporary tables. Each temporary table is private to its own session. Data inserted into a temporary table can be automatically destroyed at the transaction end (using ON COMMIT DELETE ROWS clause) or only at the end of the session (with default implicit clause ON COMMIT PRESERVE ROWS). In addition, PostgreSQL can also automatically drop the table when the transaction is finished (ON COMMIT DROP). A workaround exists and will be proposed later in this guide.
There\u0026rsquo;s no equivalent in PostgreSQL of the storage clause like INITTRANS and MAXEXTENTS. PostgreSQL allocates storage on a dynamic basis. Only PCTFREE, which indicates a percentage of size left free in a block, has an equivalent in fillfactor under PostgreSQL. However PCTUSED has no equivalent and has no sense regarding how PostgreSQL manages its storage.
References:
CREATE TABLE Virtual Columns # To replace virtual columns, PostgreSQL supports generated columns, introduced in version 12. A generated column is a special column which is always computed from other columns. Only STORED capability is implemented; a VIRTUAL generated column may be added at a future major release.
Basic example of a table with a virtal column with Oracle:
CREATE TABLE employees ( id NUMBER, first_name VARCHAR2(10), salary NUMBER(9,2), commission NUMBER(3), salary2 NUMBER GENERATED ALWAYS AS (ROUND(salary*(1+commission/100),2)) VIRTUAL, ); This could be ported in PostgreSQL with the following syntax:
CREATE TABLE employees ( id BIGINT, first_name VARCHAR(10), salary DOUBLE PRECISION, commission INTEGER, salary2 DOUBLE PRECISION GENERATED ALWAYS AS (ROUND((salary*(1+commission/100))::numeric,2)) STORED ); To emulate a non-stored data like VIRTUAL works with Oracle, views are usually the best solution.
CREATE TABLE employees ( id BIGINT, first_name VARCHAR(10), salary DOUBLE PRECISION, commission INTEGER ); CREATE VIEW virt_employees AS SELECT id, first_name, salary, commission, (ROUND((salary*(1+commission/100))::numeric,2)) salary2 FROM employees; References:
Generated column CREATE TABLE CREATE VIEW Index-Organized Tables # PostgreSQL has no direct equivalent of the IOT.
It\u0026rsquo;s possible to physically sort a table in the same order as one of its indexes thanks to the CLUSTER statement. However, each following write will be written in any available space in the table, not taking the index\u0026rsquo;s order into account. It\u0026rsquo;s possible to reduce this phenomenon by reducing the fillfactor to a smaller value (than the default 100) to let space to the new versions of a record, as a new version is put on the same page as the original one if free space is sufficient.
An Index Organized Table, or clustered table, can bring a large improvement on the range scan type queries, where a consecutive range of records of a table are accessed by a query. For instance, a query returning all the customers whose name start with MAR (SELECT * FROM clients WHERE nom LIKE 'MAR%' ) will benefit from an IOT. Reading will be faster as all records pointed by the index will be in the same block, or in a few consecutive blocks.
CLUSTER is thus a one-time operation, that should be performed again more or less frequently, depending on the write rate in the table, and the data maintenance window. One has to keep in mind that this operation is heavy and requires an exclusive lock that will block all reads and writes during the rebuild. Please note that no reindexation is necessary following a CLUSTER, as the indexes are already rebuilt during the operation.
The following example illustrates a significant performance improvement on a simple table containing 10 millions of records. The query runtime is divided by two after clustering it on the appropriate index.
Objects creation:
CREATE TABLE t6 (i SERIAL PRIMARY KEY, v INTEGER); INSERT INTO t6 (v) SELECT round(random()*10000) FROM generate_series(1, 10000000); CREATE INDEX idx_t6_v ON t6 (v); The query runtime is consistent, as data is cached:
SELECT count(*) FROM t6 WHERE v BETWEEN 100 AND 1000; -- count -- -------- -- 902274 -- -- Time: 350,100 ms This table is then clustered over the idx_t6_v index:
CLUSTER t6 USING idx_t6_v; The runtime has been divided by a factor of two:
SELECT count(*) FROM t6 WHERE v BETWEEN 100 AND 1000; -- count -- -------- -- 902274 -- -- Time: 148,755 ms References:
CLUSTER External tables # External tables make it possible to interact with CSV files from an Oracle database. This can be emulated through a Foreign Data Wrapper, as implemented by PostgreSQL in respect with the SQL/MED extension to SQL. This new feature makes it possible to declare Foreign Data Wrappers (FDW) which allow for remote access to objects outside of the database: another database, a CSV file, etc…
Given an external table\u0026rsquo;s definition for Oracle:
CREATE OR REPLACE DIRECTORY ext AS \u0026#39;/usr/tmp/\u0026#39;; CREATE TABLE ext_tab ( empno CHAR(4), ename CHAR(20), job CHAR(20), deptno CHAR(2) ) ORGANIZATION EXTERNAL ( TYPE oracle_loader DEFAULT DIRECTORY ext ACCESS PARAMETERS ( RECORDS DELIMITED BY NEWLINE BADFILE \u0026#39;bad_%a_%p.bad\u0026#39; LOGFILE \u0026#39;log_%a_%p.log\u0026#39; FIELDS TERMINATED BY \u0026#39;,\u0026#39; MISSING FIELD VALUES ARE NULL REJECT ROWS WITH ALL NULL FIELDS (empno, ename, job, deptno)) LOCATION (\u0026#39;demo1.dat\u0026#39;) ) PARALLEL REJECT LIMIT 0 NOMONITORING; It will be translate this way in PostgreSQL:
CREATE EXTENSION file_fdw; CREATE SERVER ext FOREIGN DATA WRAPPER file_fdw; CREATE FOREIGN TABLE ext_tab ( empno CHAR(4), ename CHAR(20), job CHAR(20), deptno CHAR(2) ) SERVER ext OPTIONS(filename \u0026#39;/usr/tmp/demo1.dat\u0026#39;, format \u0026#39;csv\u0026#39;, delimiter \u0026#39;,\u0026#39;); If the sole pupose is loading data, please note that PostgreSQL\u0026rsquo;s COPY statement is an alternative to the creation of a foreign data wrapper. For example, to load the example\u0026rsquo;s CSV file, one only has to run the following statement:
COPY ext_table FROM \u0026#39;/usr/tmp/demo1.csv\u0026#39; WITH CSV; References:
file_fdw COPY Global temporary tables # The Oracle GLOBAL TEMPORARY TABLE object has no equivalent in PostgreSQL. As a reminder, a global temporary table is a table whose structure is permanent, but whose content is temporary, i.e. specific to each user session.
Several solutions exist to carry these objects.
Depending on usage, it may happen that a classic table can meet the need, with a simple truncation of the table with TRUNCATE command on first use. But this prevents a use of the table by several users in parallel.
The pgtt extension, developed by Gilles Darold, emulates how global temporary tables work. But his use requires the extension library to be loaded once the user is logged in.
It is also possible to build your own temporary tables globally as follows:
create a set of tables in a dedicated schema with the structure of global temporary tables to emulate; these tables will serve as a model for creating temporary tables; associate a comment to each table to indicate the mode of operation of the temporary table during transaction COMMITs (ON COMMIT PRESERVE ROWS or ON COMMIT DROP); create a procedure or function for initializing a temporary table with a pre-existing table as a template; in PL/pgSQL code, call this procedure or function at the first using the global temporary table. CREATE SCHEMA IF NOT EXISTS gtt_schema; CREATE TABLE gtt_schema.gtt_table_1 ( col1 INTEGER, col2 TEXT ); COMMENT ON TABLE gtt_schema.gtt_table_1 IS \u0026#39;ON COMMIT PRESERVE ROWS\u0026#39;; CREATE OR REPLACE PROCEDURE prepare_temp_table(p_relname varchar) AS $$ DECLARE v_temp_schema varchar = \u0026#39;gtt_schema\u0026#39;; v_temp_desc varchar; BEGIN -- Reading the comment associated with the table v_temp_desc := pg_catalog.obj_description( (format(\u0026#39;%s.%s\u0026#39;, v_temp_schema, p_relname))::regclass, \u0026#39;pg_class\u0026#39; ); -- Creating the temporary table EXECUTE format( \u0026#39;CREATE TEMP TABLE %2$s (LIKE %1$s.%2$s) %3$s\u0026#39;, v_temp_schema, p_relname, CASE WHEN v_temp_desc ~* \u0026#39;delete\u0026#39; THEN \u0026#39;ON COMMIT DELETE ROWS\u0026#39; WHEN v_temp_desc ~* \u0026#39;drop\u0026#39; THEN \u0026#39;ON COMMIT DROP\u0026#39; ELSE \u0026#39;ON COMMIT PRESERVE ROWS\u0026#39; END ); -- If the temporary table already exists, empty it EXCEPTION WHEN SQLSTATE \u0026#39;42P07\u0026#39; THEN EXECUTE format(\u0026#39;TRUNCATE %s\u0026#39;, p_relname); END; $$ LANGUAGE plpgsql; CALL prepare_temp_table(\u0026#39;gtt_table_1\u0026#39;); References:
CREATE TABLE `}),e.add({id:7,href:"/from-oracle-to-postgresql/triggers-conversion/",title:"Triggers conversion",section:"PL/SQL to PL/pgSQL porting",content:` Triggers conversion # Structure of a trigger # In Oracle, a trigger declaration embeds the triggers code. In PostgreSQL, a trigger and a trigger function are two distinct objects: the trigger calls a trigger function depending on the events it must act upon.
For example, the print_salary_changes trigger in Oracle:
CREATE OR REPLACE TRIGGER print_salary_changes BEFORE DELETE OR INSERT OR UPDATE ON emp FOR EACH ROW WHEN (new.empno \u0026gt; 0) BEGIN ... END; will be split in two objects during the rewrite:
CREATE OR REPLACE FUNCTION trigger_fct_print_salary_changes() RETURNS TRIGGER AS $$ BEGIN ... END; $$ LANGUAGE plpgsql; CREATE OR REPLACE TRIGGER print_salary_changes BEFORE DELETE OR INSERT OR UPDATE ON emp FOR EACH ROW WHEN (NEW.empno \u0026gt; 0) EXECUTE FUNCTION tgr_print_salary_changes(); Please note that the trigger function has no parameter and returns a TRIGGER type, specific to a trigger function. The trigger declaration is almost the same between both RDBMS.
Triggers on statements need some rewriting on their declaration. In Oracle, when the FOR EACH ROW clause is not present, the resulting trigger is a FOR EACH STATEMENT. In PostgreSQL, the default trigger is FOR EACH ROW. So FOR EACH STATEMENT triggers have to be converted. Ora2Pg takes care of this.
This FOR EACH STATEMENT trigger in Oracle:
CREATE OR REPLACE TRIGGER Log_emp_update AFTER UPDATE ON Emp_tab BEGIN INSERT INTO Emp_log (Log_date, Action) VALUES (SYSDATE, \u0026#39;Emp_tab COMMISSIONS CHANGED\u0026#39;); END; will be rewritten this way in PostgreSQL:
CREATE OR REPLACE FUNCTION trigger_fct_log_emp_update() RETURNS TRIGGER AS $$ BEGIN INSERT INTO emp_log (log_date, action) VALUES (LOCALTIMESTAMP, \u0026#39;Emp_tab COMMISSIONS CHANGED\u0026#39;); END; $$ LANGUAGE plpgsql; CREATE OR REPLACE TRIGGER log_emp_update AFTER UPDATE ON emp_tab FOR EACH STATEMENT EXECUTE FUNCTION trigger_fct_log_emp_update(); PostgresQL accepts the following DML triggers:
BEFORE after AFTER; FOR EACH ROW and FOR EACH STATEMENT; on DELETE, UPDATE, INSERT (COPY is managed by the INSERT trigger) and TRUNCATE; the UPDATE OF nom_colonne_1 [, nom_colonne_2 … ] clause is also supported; conditional, with the WHEN (condition) clause. References:
Trigger Functions CREATE TRIGGER Trigger return value # PostgreSQL requires that the record is returned in a BEFORE trigger. If NULL is returned (or nothing at all), the record is not updated. This is different from Oracle, where this return value is implicit.
Thus, the following trigger from Oracle:
CREATE TRIGGER gen_id FOR produit BEFORE INSERT DECLARE noitem INTEGER; As BEGIN SELECT max(no_produit) INTO noitem FROM produit; NEW.no_produit := noitem+1; END; will have to be converted this way:
CREATE FUNCTION gen_id () RETURNS TRIGGER AS $$ DECLARE noitem INTEGER; BEGIN SELECT INTO noitem max(no_produit) FROM produit; IF noitem ISNULL THEN noitem:=0; END IF; NEW.no_produit:=noitem+1; RETURN NEW; END; $$ LANGUAGE \u0026#39;plpgsql\u0026#39;; CREATE TRIGGER trig_before_ins_produit BEFORE INSERT ON produit FOR EACH ROW EXECUTE PROCEDURE gen_id(); DML Triggers # Those triggers will need some work. First, :new and :old pseudo-tables in an Oracle trigger will have to be converted to NEW and OLD in PostgreSQL.
Finally, the INSERTING, UPDATING, and DELETING operation codes must be replaced with a test on the TG_OP valiable: TG_OP = 'INSERT', TG_OP = 'UPDATE' and TG_OP = 'DELETE'.
Oracle\u0026rsquo;s following trigger:
CREATE OR REPLACE TRIGGER testtgop BEFORE INSERT OR DELETE OR UPDATE ON emp FOR EACH ROW BEGIN IF INSERTING THEN ... ELSIF UPDATING THEN ... ELSIF DELETING THEN ... END IF; END; will be converted this way:
CREATE OR REPLACE FUNCTION trigger_fct_testtgop() RETURNS TRIGGER AS $$ BEGIN IF TG_OP = \u0026#39;INSERT\u0026#39; THEN ... ELSIF TG_OP = \u0026#39;UPDATE\u0026#39; THEN ... ELSIF TG_OP = \u0026#39;DELETE\u0026#39; THEN ... END IF; END; $$ LANGUAGE plpgsql; CREATE OR REPLACE TRIGGER testtgop BEFORE DELETE OR INSERT OR UPDATE ON emp FOR EACH ROW EXECUTE PROCEDURE trigger_fct_testtgop(); INSTEAD OF triggers # This trigger type requires the same adaptation as the DML triggers.
DDL and event triggers # PostgreSQL has event triggers which are functionally similar to Oracle\u0026rsquo;s DDL triggers. Unlike regular triggers, which are attached to a single table and capture only DML events, event triggers are global to a particular database and are capable of capturing DDL events.
An event trigger fires whenever the event with which it is associated occurs in the database in which it is defined. Currently, only four events are supported:
before the execution of a DDL command (CREATE, ALTER, DROP, SECURITY LABEL, COMMENT, GRANT or REVOKE); after the execution of this same set of commands; any operation that drops database objects; before a table is rewritten by some actions of the commands ALTER TABLE and ALTER TYPE. Event triggers require a complete rewrite in any procedural language that includes event trigger support, or in C, but not in plain SQL.
References:
Event triggers `}),e.add({id:8,href:"/from-oracle-to-postgresql/conditional-expressions/",title:"Conditional expressions",section:"Porting SQL queries",content:` Conditional expressions # Although Oracle as support for the different conditional expressions as specified by the SQL standard, far too many SQL queries still use Oracle\u0026rsquo;s historical functions.
DECODE # Oracle\u0026rsquo;s DECODE function is a proprietary equivalent of the standard compliant CASE clause.
Here is an example of DECODE use:
SELECT emp_name, decode( trunc((yrs_of_service + 3) / 4), 0, 0.04, 1, 0.04, 0.06 ) AS perc_value FROM employees; This should be rewritten this way:
SELECT emp_name, CASE WHEN trunc(yrs_of_service + 3) / 4 = 0 THEN 0.04 WHEN trunc(yrs_of_service + 3) / 4 = 1 THEN 0.04 ELSE 0.06 END FROM employees; Here is another example:
DECODE(\u0026#39;user_status\u0026#39;,\u0026#39;active\u0026#39;,\u0026#39;username\u0026#39;,NULL) This should be rewritten as:
CASE WHEN user_status=\u0026#39;active\u0026#39; THEN username ELSE NULL END Pay attention to the comments between WHEN and THEN, that are not supported by PostgreSQL.
References:
CASE NVL # Oracle\u0026rsquo;s NVL function is still often used, although the standard-compliant COALESCE is also available. These two functions return the first non-NULL argument of a list. Of course, PostgreSQL only implements the standard compliant function, COALESCE. Replacing NVL with COALESCE should be sufficient.
Thus, the following query:
SELECT NVL(description, short_description, \u0026#39;(none)\u0026#39;) FROM articles; will be easily converted to:
SELECT COALESCE(description, short_description, \u0026#39;(none)\u0026#39;) FROM articles; References:
COALESCE ROWNUM # Oracle presents a ROWNUM pseudo-column which can be used to number a query\u0026rsquo;s result lines. The ROWNUM can be used to number the lines, or to limit the number of lines returned by a query.
ROWNUM for numbering # In the first case, numbering the lines of a result set, the query should be rewritten to make use of the row_number() window function. Though Oracle recommends using the standard compliant row_number() function, ROWNUM is still frequently used in a query:
SELECT ROWNUM, * FROM employees; This will be rewritten as:
SELECT row_number() OVER () AS rownum, * FROM employees; One should pay attention to a query using ORDER BY and ROWNUM to number the lines returned by a query. Indeed, the sort is performed after the rownum assignment. These queries should be double-checked.
ROWNUM and limiting results # To limit the set returned by a query, the ROWNUM predicates should be replaced by LIMIT/OFFSET.
The following query returns the first 10 lines of the employees table in Oracle:
SELECT * FROM employees WHERE ROWNUM \u0026lt; 11; It will be rewritten as this in PostgreSQL:
SELECT * FROM employees LIMIT 10; If the result need to be sorted in a particular way, Oracle will operate a sorting node with ORDER BY after adding the ROWNUM pseudo-column (COUNT STOPKEY), as shown in the execution plan of the previous query:
--------------------------------------------------------------------------------- | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | --------------------------------------------------------------------------------- | 0 | SELECT STATEMENT | | 10 | 690 | 3 (34)| 00:00:01 | | 1 | SORT ORDER BY | | 10 | 690 | 3 (34)| 00:00:01 | |* 2 | COUNT STOPKEY | | | | | | | 3 | TABLE ACCESS FULL | EMPLOYEES | 10 | 690 | 2 (0)| 00:00:01 | --------------------------------------------------------------------------------- A query limiting with Oracle is generally written this way (to work around the fact that ROWNUM is performed before the sorting):
SELECT ROWNUM, r.* FROM (SELECT * FROM t1 ORDER BY col) r WHERE ROWNUM BETWEEN 1 AND 10; On the opposite, PostgreSQL will first sort, then limit the result. When PostgreSQL has both a LIMIT and a sort with ORDER BY, the sort will be performed first. This should be written this way in PostgreSQL:
SELECT * FROM employees ORDER BY salary DESC LIMIT 10; QUERY PLAN ------------------------------------------------------------------- Limit (cost=81.44..81.46 rows=10 width=8) -\u0026gt; Sort (cost=81.44..87.09 rows=2260 width=8) Sort Key: salary DESC -\u0026gt; Seq Scan on employees (cost=0.00..32.60 rows=2260 width=8) References:
LIMIT and OFFSET Window Functions `}),e.add({id:9,href:"/from-oracle-to-postgresql/control-structures/",title:"Control structures",section:"PL/SQL to PL/pgSQL porting",content:` Control structures # Loops and control structures don\u0026rsquo;t require a lot of work, except for the GOTO and FORALL instructions.
FOR REVERSE loop # The FOR ... REVERSE has also the peculiarity of needing to revers the min and max boundaries in FOR ... IN ... REVERSE min..max.
For an Oracle code:
FOR i IN REVERSE 1..10 BY 2 LOOP ... END LOOP; One should convert to:
FOR i IN REVERSE 10..1 BY 2 LOOP ... END LOOP; Another important difference is FOR loops on queries (other than cursors). In PL/SQL, the target variables are implicitly declared, while they have to be declared in PostgresQL. One will have to declare those variables in the DECLARE block of the function. This has the advantage of keeping the variable accessible out of the loop.
Thus, the following PL/SQL extract:
DECLARE v_date1 DATE, v_date2 DATE; BEGIN FOR r IN ( SELECT numberprgn FROM t2 WHERE status = \u0026#39;ordered\u0026#39; AND assigned_dept = \u0026#39;departt\u0026#39; ) LOOP SELECT min(datestamp) INTO v_date1 FROM T1 WHERE NUMBER = r.numberprgn AND description = \u0026#39;state1\u0026#39;; SELECT min(datestamp) INTO v_date2 FROM T1 WHERE NUMBER = r.numberprgn AND description = \u0026#39;state2\u0026#39;; END LOOP; will be converted this way, declaring v_date1 and v_date2 as timestamp data type:
DECLARE v_date1 TIMESTAMP, v_date2 TIMESTAMP; r record; BEGIN FOR r IN ( SELECT numberprgn FROM t2 WHERE status = \u0026#39;ordered\u0026#39; AND assigned_dept = \u0026#39;departt\u0026#39; ) LOOP SELECT min(datestamp) INTO STRICT v_date1 FROM T1 WHERE number = r.numberprgn AND description = \u0026#39;state1\u0026#39;; SELECT min(datestamp) INTO STRICT v_date2 FROM T1 WHERE number = r.numberprgn AND description = \u0026#39;state2\u0026#39;; END LOOP; References:
Simple Loops Porting from Oracle PL/SQL GOTO instruction # The GOTO instruction has no equivalent and imposes a rewriting. Usage of this instruction is usually not advised, but it is not that seldom used to step out of a loop or get to the next iteration.
Given this PL/SQL code:
LOOP FETCH current_cursor INTO current; EXIT WHEN curs_courant%NOTFOUND; IF v_cat = \u0026#39;YYY\u0026#39; THEN v_cat := current; GOTO BEGINNING; END IF; IF current = \u0026#39;N1\u0026#39; THEN v_cat := current; GOTO ENDING; END IF; ... \u0026lt;\u0026lt;BEGINNING\u0026gt;\u0026gt; NULL; END LOOP; \u0026lt;\u0026lt;ENDING\u0026gt;\u0026gt; CLOSE current_cursor; should be rewritten this way:
LOOP FETCH current_cursor INTO current; IF NOT FOUND THEN EXIT; END IF; IF v_cat = \u0026#39;YYY\u0026#39; THEN v_cat := current; CONTINUE; END IF; IF current = \u0026#39;N1\u0026#39; THEN v_cat := current; EXIT; END IF; ... END LOOP; CLOSE current_cursor; FORALL loops # A FORALL loop is used to iterate over the lines of an Oracle collection. As there are no collections in PostgreSQL, there is no FORALL loop either. It\u0026rsquo;s implementation is simple enough with PostgreSQL, as it is about iterating over the array replacing the collection.
Thus, the following PL/SQL procedures:
CREATE OR REPLACE PROCEDURE allEmployees IS TYPE v_array IS varray(50) OF CHAR(14); arr_emp v_array; BEGIN SELECT ename BULK COLLECT INTO arr_emp FROM emp ORDER BY ename; FORALL i IN 1..arr_emp.COUNT dbms_output.put_line(\u0026#39;|name\u0026#39;||arr_emp..(i)||\u0026#39;i\u0026#39;|| i); END allEmployees; becomes:
CREATE OR REPLACE FUNCTION allEmployees() RETURNS VOID AS $body$ DECLARE arr_emp CHAR(14)[]; BEGIN arr_emp := array ( SELECT ename FROM emp ORDER BY ename); FOR i IN array_lower(arr_emp,1)..array_upper(arr_emp,1) LOOP RAISE NOTICE \u0026#39;|name % i %\u0026#39;, arr_emp[i], i; END LOOP; END; $body$ LANGUAGE plpgsql; `}),e.add({id:10,href:"/from-oracle-to-postgresql/porting-sql-queries/",title:"Porting SQL queries",section:"Docs",content:` Porting SQL queries # DML statements compatibility # Most DML statements are compatible between Oracle and PostgreSQL. Note though that the MERGE statement doesn\u0026rsquo;t exist yet in PostgreSQL. Some restrictions exist for some window functions and recursive Common Table Expressions (CTE).
Subquery aliases # Oracle does not handle error messages while subqueries are unaliased unlike PostgreSQL. For instance, this query need to be rewritten:
SELECT \u0026lt;columns, ...\u0026gt; FROM (SELECT \u0026lt;...\u0026gt; ) WHERE \u0026lt;conditions\u0026gt; as:
SELECT \u0026lt;columns, ...\u0026gt; FROM (SELECT \u0026lt;...\u0026gt; ) sub1 WHERE \u0026lt;conditions\u0026gt; Implicit conversions # Many implicit conversion to and from a text type have been removed since PostgreSQL 8.3.
For instance, one cannot write this type of query:
CREATE TABLE depts ( number CHAR(2), dname VARCHAR(25) ); SELECT * FROM depts WHERE number BETWEEN 0 AND 42; -- ERROR: operator does not exist: character \u0026gt;= INTEGER -- LIGNE 1 : SELECT * FROM depts WHERE number BETWEEN 0 AND 42; In order to run this query, one has to explicitly declare the conversion to be performed:
SELECT * FROM depts WHERE number::INTEGER BETWEEN 0 AND 42; -- or (more SQL compliant) SELECT * FROM depts WHERE CAST(id AS INTEGER) BETWEEN 0 AND 42; With Oracle, this conversion is implicit (but will mask a potential performance problem as it will force a type conversion).
HAVING and GROUP BY clauses # Even though Oracle\u0026rsquo;s documentation stipulates that the GROUP BY clause precedes the HAVING clause, Oracle\u0026rsquo;s grammar permits the opposite. Those queries having HAVING before GROUP BY will have to be corrected.
This query, for example:
SELECT * FROM test HAVING count(*) \u0026gt; 3 GROUP BY i; will have to be converted this way to be run in PostgreSQL:
SELECT * FROM test GROUP BY i HAVING count(*) \u0026gt; 3; References:
The GROUP BY and HAVING Clauses ROWID # In very rare occasions, some SQL queries use Oracle\u0026rsquo;s ROWID column, for instance to deduplicate records. The ROWID column is the physical location of a record in a table. PostgreSQL\u0026rsquo;s equivalent is ctid.
More specifically, Oracle\u0026rsquo;s ROWID is a record\u0026rsquo;s logical address, in the OOOOOO.FFF.BBBBBB.RRR form, where O is the object\u0026rsquo;s number, F the file, B the block\u0026rsquo;s number, and R the row\u0026rsquo;s number in this block. The format may vary if the table is in a BIG FILE TABLESPACE, but the principle stays the same.
PostgreSQL\u0026rsquo;s ctid contains only the block number and the row\u0026rsquo;s number in this block. There is no other localisation information. The ctid is only unique inside a table. Because of that, a query returning ctids from a partitioned table may have duplicated. In this peculiar case, one can add the tableoid column (the table\u0026rsquo;s id in the catalog), which will distinguish between duplicates coming from different partitions.
Another difference is that an update doesn\u0026rsquo;t change a record\u0026rsquo;s rowid in Oracle, while it does change the ctid in PostgreSQL.
This access method should be avoided as much as possible.
References:
System Columns Minus operator conversion # The MINUS operator has to be converted to EXCEPT for PostgreSQL. The other set operations UNION, UNION ALL, and INTERSECT don\u0026rsquo;t need any conversion.
Thus, the following query returns all inventory products which have never been in a command. It can be written like this for Oracle:
SELECT product_id FROM inventories MINUS SELECT product_id FROM order_items ORDER BY product_id; It will be written this way for PostgreSQL:
SELECT product_id FROM inventories EXCEPT SELECT product_id FROM order_items ORDER BY product_id; References:
Combining Queries (UNION, INTERSECT, EXCEPT) Window Functions # The queries using window functions don\u0026rsquo;t usually need a lot of work.
Oracle proposes an ORDER SIBLINGS BY clause. The SIBLINGS keyword has no equivalent and is anyway only used for hierarchy processing, with CONNECT BY. This kind of query has to be rewritten anyway.
The PARTITION BY don\u0026rsquo;t need any adaptation, neither the windowing clause (RANGE ... or ROWS ...).
Most of Oracle\u0026rsquo;s general usage window functions exist in PostgreSQL. Some functions still have no equivalent for the moment.
RATIO_TO_REPORT will need to be rewritten (using a division on the sum on the window). LISTAGG function will need to be rewritten using array_agg and array_to_string. Please note though that PostgreSQL\u0026rsquo;s extension capabilities make it possible to write new aggregate and window functions, making it possible to write the missing functions.
References:
Window Functions Tutorial Window Functions Window Function Calls Aggregate Functions Recursive CTE # Oracle\u0026rsquo;s grammar makes no difference between a standard CTE and a recursive CTE, while PostgreSQL does and requires a correct usage of WITH and WITH RECURSIVE. One will need to correct recursive CTE, which should include a UNION ALL and a reference to the common table expression itself.
The following query does a very simple recursion:
WITH recursion (a) AS ( SELECT 1 AS a FROM dual UNION ALL SELECT a + 1 FROM recursion WHERE a \u0026lt; 10 ) SELECT * FROM recursion; Here it is, rewritten for PostgreSQL:
WITH RECURSIVE recursion (a) AS ( SELECT 1 AS a UNION ALL SELECT a + 1 FROM recursion WHERE a \u0026lt; 10 ) SELECT * FROM recursion; The WITH clause also proposes some extensions in Oracle, to describe how to perform the recursion (search_clause) and the loop detection (cycle_clause). Cycle detection has already been tackled in \u0026ldquo; Hierarchical querying \u0026quot; section of this document.
References:
SELECT Cycle Detection MERGE # MERGE command allows to make insertions or updates of tables depending on whether the rows already exist or not. The typical syntax for the statement looks like this:
MERGE INTO destination_table USING source_table ON (condition) WHEN MATCHED THEN update_clause WHEN NOT MATCHED THEN insert_clause; But versions prior to PostgreSQL 15 do not support the syntax MERGE from the SQL standard. On the other hand, we can emulate this instruction with a INSERT. It is necessary to distinguish here several cases, according to the presence or not of WHEN MATCHED and WHEN NOT MATCHED clauses.
If there is no WHEN NOT MATCHED clause, a simple UPDATE is required:
UPDATE destination_table update_clause USING source_table WHERE join_condition; If there is no WHEN MATCHED clause, using an INSERT on non existing rows is more relevant:
INSERT INTO destination_table SELECT ... FROM source_table WHERE join_condition ON CONFLICT DO NOTHING; If the two clauses WHEN MATCHED and WHEN NOT MATCHED are present, the translation becomes:
INSERT INTO destination_table SELECT ... FROM source_table WHERE join_condition ON CONFLICT DO UPDATE update_clause Sometimes, on Oracle, a DELETE WHERE ... is present after the UPDATE of the WHEN MATCHED clause. In this case, we can add a simple query DELETE before or after the INSERT. We can also set this DELETE to inside the INSERT, as a common table expression (CTE).
References:
ON CONFLICT Clause Hints management # Oracle\u0026rsquo;s optimizer accepts hints, which make it possible for the DBA to force the optimizer into using a plan it considers isn\u0026rsquo;t the best. Those hints are expressed as commends and will be ignored by PostgreSQL, which has no hints.
Nevertheless, a query making use of a hint should have its execution plan analyzed carefully, to be sure that it will work with PostgreSQL.
The plan will be checked with EXPLAIN ANALYZE, which displays both the estimates of the optimizer and what really occurred during execution. One should look for a large discrepancy between estimated and real selectivity, for each node. This will indicate what the optimizer doesn\u0026rsquo;t understand in the query. Often, this is only the consequence of too imprecise statistics. This can be corrected in several way.
First, it\u0026rsquo;s possible to make statistics collection more thorough, by raising the amount of sampled data. This is controlled by the default_statistics_target parameter. This can be done globally or per column of each table. A higher value will make statistics collection consume more resources, and will make query planning longer, as more statistics will have to be analyzed to make a decision. The default value of 100 is good for most tables and data sets, so one usually only change statistics on the very few columns requiring it. This is done with ALTER TABLE … ALTER COLUMN … SET STATISTICS …. It\u0026rsquo;s also possible to artificially force the number of distinct values statistic on a column with ALTER TABLE … SET COLUMN … SET n_distinct = …, as this statistic is quite difficult to get right for the statistics collector.
Sometimes, a query rewrite is the solution: queries can be written in ways that prevent the optimizer from doing good estimations. This is as true for PostgreSQL as it is for Oracle.
`}),e.add({id:11,href:"/from-oracle-to-postgresql/views-migration/",title:"Views migration",section:"Porting database objects",content:` Views migration # Simple views are ported with no difficulty to PostgreSQL.
A view is updatable as long as it only references only one table (or another updatable view) and doesn\u0026rsquo;t contain more complex operators, group by, join types, etc. PostgreSQL even supports views defined with CHECK OPTION attribute to prevent updated or inserted rows to being invisible with view\u0026rsquo;s conditions.
References:
CREATE VIEW XML views # Some views return their result as XML. Porting these is quite quick. Only the XMLELEMENT function is incompatible between Oracle and PostgreSQL, so it\u0026rsquo;s necessary to add the name directive, which becomes the name of the XML element for PostgreSQL.
Thus, this view definition, in Oracle:
CREATE VIEW warehouse_view OF XMLTYPE XMLSCHEMA \u0026#34;http://www.oracle.com/xwarehouses.xsd\u0026#34; ELEMENT \u0026#34;Warehouse\u0026#34; WITH OBJECT ID (extract(OBJECT_VALUE, \u0026#39;/Warehouse/Area/text()\u0026#39;).getnumberval()) AS SELECT XMLELEMENT(\u0026#34;Warehouse\u0026#34;, XMLFOREST(WarehouseID AS \u0026#34;Building\u0026#34;, area AS \u0026#34;Area\u0026#34;, docks AS \u0026#34;Docks\u0026#34;, docktype AS \u0026#34;DockType\u0026#34;, wateraccess AS \u0026#34;WaterAccess\u0026#34;, railaccess AS \u0026#34;RailAccess\u0026#34;, parking AS \u0026#34;Parking\u0026#34;, VClearance AS \u0026#34;VClearance\u0026#34;)) FROM warehouse_table; will be converted to this in PostgreSQL:
CREATE VIEW warehouse_view SELECT XMLELEMENT(name \u0026#34;Warehouse\u0026#34;, XMLFOREST(WarehouseID AS \u0026#34;Building\u0026#34;, area AS \u0026#34;Area\u0026#34;, docks AS \u0026#34;Docks\u0026#34;, docktype AS \u0026#34;DockType\u0026#34;, wateraccess AS \u0026#34;WaterAccess\u0026#34;, railaccess AS \u0026#34;RailAccess\u0026#34;, parking AS \u0026#34;Parking\u0026#34;, VClearance AS \u0026#34;VClearance\u0026#34;)) FROM warehouse_table; References:
CREATE VIEW Materialized views # Materialized views exist in PostgreSQL, and behave in a similar way than Oracle. However, they are not automatically refreshed, and queries aren\u0026rsquo;t rewritten to use them transparently, though.
The materialized view needs to be refreshed on demand by calling REFRESH MATERIALZED VIEW, that perform a complete rebuild of the view.
Thus, a Oracle materialized view, defined as below:
CREATE MATERIALIZED VIEW emp_aggr_mv BUILD DEFERRED REFRESH FORCE ON DEMAND AS SELECT deptno, SUM(sal) AS sal_by_dept FROM emp GROUP BY deptno; Will be ported in PostgreSQL with:
CREATE MATERIALIZED VIEW emp_aggr_mv AS SELECT deptno, SUM(sal) AS sal_by_dept FROM emp GROUP BY deptno WITH NO DATA; Materialized view logs and other ON COMMIT behaviors have not been implemented yet in PostgreSQL. Emulating incremental refreshment could be done by declaring triggers or using external projects like pg_ivm.
References:
CREATE MATERIALIZED VIEW pg_ivm `}),e.add({id:12,href:"/from-oracle-to-postgresql/hierarchical-querying/",title:"Hierarchical querying",section:"Porting SQL queries",content:` Hierarchical querying # Oracle provides a CONNECT BY function to explore a hierarchical tree. This proprietary functionality has advanced features such as loop detection and provides pseudo-columns such as depth and path.
Since version 14, many advanced features are available with PostgreSQL. For earlier versions, significant work must be performed to port queries using theses clauses.
CONNECT BY # Here is a SQL query exploring the emp table\u0026rsquo;s hierarchy. The mgr column in this table points to the manager of the employee. If it is NULL, then this employee is on top of the hierarchy (START WITH mgr IS NULL). The link between the employee and its manager is built with the CONNECT BY PRIOR empno = mgr clause, indicating that the mgr is the empno identifier of the precedent level of hierarchy.
SELECT empno, ename, job, mgr FROM emp START WITH mgr IS NULL CONNECT BY PRIOR empno = mgr This is converted with the help of a recursive query (WITH RECURSIVE). Recursion is initiated in a first query retrieving the lines matching the START WITH condition of previous query: mgr is NULL. Recursion continues then with the following query doing a join between the emp table and the virtual emp_hierarchy table defined by the WITH RECURSIVE clause. The join condition matches the previous CONNECT BY. Here, emp_hierarchy has been aliased to prior, to better illustrate the conversion.
Here is a possible rewriting then:
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr) AS ( SELECT empno, ename, job, mgr FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) ) SELECT * FROM emp_hierarchy; One should pay attention to the returned order of rows with the WITH RECURSIVE query. Oracle uses by default a depth-first algorithm to implement CONNECT BY. It will explore each branch before going to the next. WITH RECURSIVE is breadth-first, exploring each level before going onto the next.
It\u0026rsquo;s possible to get the CONNECT BY order though, by sorting on a path column, such as the one one would build to emulate SYS_CONNECT_BY_PATH:
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, path) AS ( SELECT empno, ename, job, mgr, ARRAY[ename::TEXT] AS path FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.path || emp.ename::TEXT AS path FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) ) SELECT empno, ename, job FROM emp_hierarchy AS emp ORDER BY path; Oracle 11g has changed the default return order of CONNECT BY queries.
LEVEL pseudo-column # One can get the hierarchy depth of an element using the LEVEL pseudo-column.
SELECT empno, ename, job, mgr, level FROM emp START WITH mgr IS NULL CONNECT BY PRIOR empno = mgr Porting LEVEL is easy. Initialize a column called level to 1, then increment it in each new recursive join:
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, level) AS ( SELECT empno, ename, job, mgr, 1 AS level FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.level + 1 FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) ) SELECT * FROM emp_hierarchy; SYS_CONNECT_BY_PATH function # SYS_CONNECT_BY_PATH is used to display the path taken to reach a record, each element separated by a given character. For instance, the following query returns all managers of an employee:
SELECT empno, ename, job, mgr, SYS_CONNECT_BY_PATH(ename, \u0026#39;/\u0026#39;) AS path FROM emp START WITH mgr IS NULL CONNECT BY PRIOR empno = mgr; This is also quite easy to convert. One can add a root path \u0026lsquo;/\u0026rsquo; in the first query of the recursion, then keep concatenating current path to previous path.
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, path) AS ( SELECT empno, ename, job, mgr, \u0026#39;/\u0026#39; || ename AS path FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.path || \u0026#39;/\u0026#39; || emp.ename FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) ) SELECT * FROM emp_hierarchy; Another way is to use an array to store the path, then convert it to any other representation (here the same as SYS_CONNECT_BY_PATH(ename, '/')). This can be used to detect loops all at once:
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, path) AS ( SELECT empno, ename, job, mgr, ARRAY[ename::TEXT] AS path FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.path || emp.ename::TEXT AS path FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) ) SELECT empno, ename, job, array_to_string(path, \u0026#39;/\u0026#39;) AS path FROM emp_hierarchy AS emp; NOCYCLE clause # The following Oracle query:
SELECT empno, ename, job, mgr FROM emp START WITH mgr IS NULL CONNECT BY NOCYCLE PRIOR empno = mgr; will be converted to PostgreSQL this way:
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, path, is_cycle) AS ( SELECT empno, ename, job, mgr, ARRAY[ename::TEXT] AS path, false AS is_cycle FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.path || emp.ename::TEXT AS path, emp.ename = ANY(prior.path) AS is_cycle FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) WHERE is_cycle = false ) SELECT empno, ename, job, mgr FROM emp_hierarchy AS emp WHERE is_cycle = false; CONNECT_BY_IS_CYCLE clause # The CONNECT_BY_IS_CYCLE clause returns 1 if the current record has a child that is also its ancestor. Else it will return 0. This can be emulated from the previous query, with a conditional expression, and by removing the last filter:
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, level, path, is_cycle) AS ( SELECT empno, ename, job, mgr, 1 AS level, ARRAY[ename::TEXT] AS path, false AS is_cycle FROM emp WHERE mgr = 10000 UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.level + 1 AS level, prior.path || emp.ename::TEXT AS path, emp.ename = ANY(prior.path) AS is_cycle FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) WHERE is_cycle = false ) SELECT *, is_cycle::int connect_by_is_cycle FROM emp_hierarchy AS emp; ORDER SIBLINGS BY clause # The ORDER SIBLINGS BY clause can be emulated by starting from the recursive query used for SYS_CONNECT_BY_PATH, and sort on the path array column, as arrays are sorted by comparing elements from first to last:
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, path) AS ( SELECT empno, ename, job, mgr, \u0026#39;/\u0026#39; || ename AS path FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.path || \u0026#39;/\u0026#39; || emp.ename FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) ) SELECT * FROM emp_hierarchy ORDER BY path; However, this emulation only works with an ascending sort. Applying a descending sort does not return the expected result.
CONNECT_BY_ROOT clause # The CONNECT_BY_ROOT clause returns the root of the hierarchy for each element. In the following example, the last column will return the topmost person in the hierarchy of the current employee:
SELECT empno, ename, job, mgr AS direct_mgr, CONNECT_BY_ROOT ename AS mgr FROM emp START WITH mgr IS NULL CONNECT BY mgr = PRIOR empno ORDER SIBLINGS BY ename DESC; This is converted the same way as the SYS_CONNECT_BY_PATH query. The path array can simply be used to get the topmost element.
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, path) AS ( SELECT empno, ename, job, mgr, ARRAY[ename::TEXT] AS path FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.path || emp.ename::TEXT AS path FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) ) SELECT empno, ename, job, path[1] AS connect_by_root FROM emp_hierarchy AS emp; CONNECT_BY_ISLEAF clause # CONNECT_BY_ISLEAF takes no arguments. It specifies whether current row (called leaf) is no longer connected to a deeper row through the hierarchy tree. The value 0 is returned if deeper rows exist and 1 if current row is the last in the hierarchy.
SELECT empno, ename, job, mgr, CONNECT_BY_ROOT ename AS mgr, CONNECT_BY_ISLEAF ASisleaf, SYS_CONNECT_BY_PATH(ename, \u0026#39;/\u0026#39;) AS path FROM emp START WITH mgr IS NULL CONNECT BY mgr = PRIOR empno CONNECT_BY_ISLEAF is a bit harder to emulate, as we are using a breadth-first algorithm: we can\u0026rsquo;t know if a record is a leaf before having done the next iteration of the recursive join. We\u0026rsquo;ll have to identify leaf records with a second pass.
For instance, we can use a window function to compare each found path to the following (sorted by path): if the next path is longer than the current, we are not a leaf. Else, we are a leaf. Here is a rewrite doing this:
WITH RECURSIVE emp_hierarchy (empno, ename, job, mgr, path) AS ( SELECT empno, ename, job, mgr, ARRAY[ename::TEXT] AS path FROM emp WHERE mgr IS NULL UNION ALL SELECT emp.empno, emp.ename, emp.job, emp.mgr, prior.path || emp.ename::TEXT AS path FROM emp JOIN emp_hierarchy prior ON (emp.mgr = prior.empno) ) SELECT emp.empno, emp.ename, emp.job, CASE WHEN leaf.empno IS NULL THEN 1 ELSE 0 END AS isleaf FROM emp_hierarchy AS emp LEFT JOIN emp_hierarchy AS leaf ON (emp.empno = leaf.mgr) ORDER BY emp.path; `}),e.add({id:13,href:"/from-oracle-to-postgresql/pl-sql-code-conversion/",title:"PL/SQL code conversion",section:"PL/SQL to PL/pgSQL porting",content:` PL/SQL code conversion # Empty strings and NULL values # For Oracle, an empty string is NULL too. PostgreSQL makes a difference: IS NULL and empty are different.
Some queries working with Oracle may not work as expected if directly copied. The most frequent problems are comparing a column with an empty string, and concatenating with a NULL. Please refer to what has already been exposed in the previous chapter about porting queries.
When PL/SQL code is ported to PL/pgSQL, one has to mind the calling code too: if the application\u0026rsquo;s code hasn\u0026rsquo;t converted '' to NULL, then one has to be careful about when the function receives an empty string in place of a NULL value.
Here are some examples illustrating this in Oracle:
IF vidfee IS NULL THEN ... IF vidfee IS NOT NULL THEN ... For Oracle vidfee will be NULL if it is an empty string or if it is NULL, and it won\u0026rsquo;t make any difference. If this calling code accesses a function with such tests, but passing empty strings, it will work with Oracle.
It will fail with Postgresql, as it is much stricter in this regard. You\u0026rsquo;ll have to modify the IF tests in the converted PL/pgSQL function, to avoid a rewrite in the calling function.
Here is an example of converted code (first test):
IF COALESCE(vidfee, \u0026#39;\u0026#39;) = \u0026#39;\u0026#39; THEN ... In this example, if vidfee is NULL, coalesce will return '', which is what we want here.
The second test (IS NOT NULL) is a bit less intuitive:
IF (vidfee IS NOT NULL AND vidfee \u0026lt;\u0026gt; \u0026#39;\u0026#39;) THEN ... One can also start the function with a simple hack, which will greatly simplify the rest of the tests. This is not applicable to SQL though, only to PL/SQL.
IF vidfee = \u0026#39;\u0026#39; THEN vidfee := NULL END; Ora2Pg does these code conversions automatically by default, the directive NULL_EQUAL_EMPTY disables this behavior.
Queries and functions execution # When a SELECT with no INTO clause exists, it has to be replaced by PERFORM. This is also done automatically by Ora2Pg.
Thus, the following extract from a PL/SQL procedure:
BEGIN SELECT ename, sal FROM EMP WHERE empno=7902 FOR UPDATE; ... END; will be converted to:
BEGIN PERFORM ename, sal FROM EMP WHERE empno=7902 FOR UPDATE; ... END; In addition, the EXEC instruction used to retrieve into a variable the return code from a PL/SQL function doesn\u0026rsquo;t exist in PostgreSQL. This has to be rewritten by using SELECT INTO This is performed by Ora2Pg.
The following PL/SQL extract:
EXEC :a := get_version(); will be converted to:
SELECT get_version() INTO a; Dynamic queries execution # To execute a dynamically built query, Oracle provides an EXECUTE IMMEDIATE clause. In PostgreSQL, the IMMEDIATE must be removed, as it in not supported. Indeed, an EXECUTE is always executed immediately. This is performed automatically by Ora2Pg.
Furthermore, one should use quote_literal, quote_nullable and quote_ident to build a dynamic SQL query in PostgreSQL. This avoids SQL injection. This isn\u0026rsquo;t performed by Ora2Pg.
For instance, the following SQL code:
sql_stmt := \u0026#39;UPDATE employees SET salary = salary + :1 WHERE \u0026#39; || v_column || \u0026#39; = :2\u0026#39;; EXECUTE IMMEDIATE sql_stmt USING amount, column_value; should be converted this way (note the : replaced by $):
sql_stmt := \u0026#39;UPDATE employees SET salary = salary + $1 WHERE \u0026#39; || quote_literal(v_column) || \u0026#39; = $2\u0026#39;; EXECUTE sql_stmt USING amount, column_value; References:
Executing Dynamic Commands COMMIT in a routine # There is no way with PostgreSQL to COMMIT or ROLLBACK instructions inside a function or even in a procedure called by a function.
In these cases, it is advisable to perform transaction management in higher level code.
Note that, due to MVCC implementations, PostgreSQL can support long transactions more easily than Oracle. Also, some intermediate COMMIT statements can often be purely and simply deleted.
Exceptions management # Exceptions\u0026rsquo; handling is quite different between Oracle and PostgreSQL. First, Oracle\u0026rsquo;s SQLCODE is almost equivalent to PostgreSQL\u0026rsquo;s SQLSTATE. One has thus to be replaced by the other, which is performed by Ora2Pg.
But the most notable difference is the way the error is handled. If an error is triggered in a PL/SQL block, only the triggering statement is rollbacked. As a consequence, one often sees savepoints declared at the beginning of the block and ROLLBACK TO SAVEPOINT statements issued in the exception block.
PostgreSQL\u0026rsquo;s way of handling exceptions is different. When an error is trigger in a PL/pgSQL block, the whole block is rollbacked by the exception. PL/SQL constructs using SAVEPOINTS with thus be simply ported, by removing the ROLLBACK TO SAVEPOINT instructions.
The following PL/SQL code:
BEGIN SAVEPOINT s1; ... EXCEPTION WHEN ... THEN ROLLBACK TO s1; ... WHEN ... THEN ROLLBACK TO s1; ... END; will be simplified this way:
BEGIN ... EXCEPTION WHEN ... THEN ... WHEN ... THEN ... END; Some exceptions\u0026rsquo; names will also have to be replaced. Here are the errors that will have to be replaced:
Oracle PostgreSQL STORAGE_ERROR OUT_OF_MEMORY ZERO_DIVIDE DIVISION_BY_ZERO INVALID_CURSOR INVALID_CURSOR_STATE dup_val_on_index unique_violation Finally, Oracle\u0026rsquo;s raise_application_error will be converted to RAISE EXCEPTION. The following code from Oracle:
raise_application_error( -20000, \u0026#39;Unable to create a new job: a job is currently running.\u0026#39; ); must be converted this way:
RAISE EXCEPTION \u0026#39;Unable to create a new job: a job is currently running\u0026#39;; References:
PostgreSQL Error Codes Implicit Rollback after Exceptions SELECT INTO # The SELECT ... INTO ... statement will need adaptation to behave with PostgreSQL the same way it does with Oracle. PostgreSQL\u0026rsquo;s STRICT option is Oracle\u0026rsquo;s default behavior. One will have to add the STRICT keyword after INTO when an exception on NO_DATA_FOUND or TOO_MANY_ROWS exists in the same code block.
Thus, this procedure in PL/SQL:
BEGIN SELECT feegroupid INTO vsalegroup FROM feegroup WHERE feeclass = \u0026#39;V\u0026#39; AND isdefault = 1 AND ispublic = vispublic; EXCEPTION WHEN NO_DATA_FOUND THEN vidartpxvte := \u0026#39;-040\u0026#39;; RETURN vidartpxvte; WHEN TOO_MANY_ROWS THEN vidartpxvte := \u0026#39;-045\u0026#39;; RETURN vidartpxvte; END; has to be converted this way for PostgreSQL:
BEGIN SELECT feegroupid INTO STRICT vsalegroup FROM feegroup WHERE feeclass = \u0026#39;V\u0026#39; AND isdefault = 1 AND ispublic = vispublic; EXCEPTION WHEN NO_DATA_FOUND THEN vidartpxvte := \u0026#39;-040\u0026#39;; RETURN vidartpxvte; WHEN TOO_MANY_ROWS THEN vidartpxvte := \u0026#39;-045\u0026#39;; RETURN vidartpxvte; END; References:
Executing a Command with a Single-Row Result BULK COLLECT # There is no BULK COLLECT in PostgreSQL. This is used in Oracle to load the content of a query in an array, and then iterate over this array.
For example, this Oracle code:
CREATE PROCEDURE AllAuthors IS TYPE my_array IS varray(100) OF VARCHAR(25); temp_arr my_array; BEGIN SELECT author_name BULK COLLECT INTO temp_arr FROM authors ORDER BY author_name; FOR i IN temp_arr.first .. temp_arr.last LOOP DBMS_OUTPUT.put_line(i || \u0026#39;) author_name: \u0026#39; || temp_arr..(i)); END LOOP; END AllAuthors; can be translated to:
CREATE FUNCTION AllAuthors() RETURNS VOID AS $$ DECLARE temp_arr VARCHAR(25)[]; BEGIN temp_arr := (SELECT author_name FROM authors ORDER BY author_name); FOR i IN array_lower(temp_arr,1) .. array_upper(temp_arr,1) LOOP RAISE NOTICE \u0026#39;% ) author_name: %\u0026#39;, i, temp_arr..(i); END LOOP; END; $$ LANGUAGE plpgsql; instr function # PostgreSQL\u0026rsquo;s documentation proposes a PL/PgSQL implementation of Oracle\u0026rsquo;s instr in its chapter about porting from Oracle PL/SQL.
`}),e.add({id:14,href:"/from-oracle-to-postgresql/pl-sql-to-pl-pgsql-porting/",title:"PL/SQL to PL/pgSQL porting",section:"Docs",content:` PL/SQL to PL/pgSQL porting # Main differences between PL/SQL and PL/pgSQL # Although Oracle supports both PL/SQL and Java for server programming, and PotsgreSQL many languages such as PL/Perl, PL/Python, PL/R, PL/Java, etc., this part is only about porting from PL/SQL to PL/pgSQL.
PostgreSQL\u0026rsquo;s PL/pgSQL has been initially designed as a language similar to Oracle\u0026rsquo;s PL/SQL. Nevertheless, these are two different languages, and converting from one to the other takes some work.
First, please note that there is no package in PostgreSQL. A workaround is needed to emulate them.
Main differences:
no package; compiled at first execution, by session, not globally; no procedures in PostgreSQL, only functions; no autonomous transaction; no directories or similar functionality… PL/PgSQL doesn\u0026rsquo;t handle files. The last point can easily be circumvented by using one of the other PL languages that have this capability. Please also note that the language in which a function is written is of no importance to the caller.
Packages migration # An Oracle package is the logical grouping of variables and stored procedures in a namespace. There is no equivalent in PostgreSQL. To simplify the porting, Ora2Pg will create a schemas with the package names and put functions in their respective schemas. This will make it possible to use Oracle\u0026rsquo;s PACKAGE.PROCEDURE notation which will become SCHEMA.FUNCTION.
Oracle also permits creating functions nested into other functions. PostgreSQL doesn\u0026rsquo;t accept this with PL/PgSQL. All those functions will have to be extracted from their parent\u0026rsquo;s function body and declared separately.
There is no global variable in PL/PgSQL. To emulate this, one can use user variables, which will have to be declared in the postgresql.conf configuration file, at database or user level or directly used by a session with SET instruction.
Theses variables must be prefixed with an arbitary namespace, so as not to conflict with system configuration. A good practice is to prefix a variable with the schema\u0026rsquo;s name, used to emulate packages. The variable scope remains local to a session and can not persist or be shared between several sessions.
For instance, to create an id_region variable, one can use the SET command:
SET myschema.id_region = \u0026#39;38\u0026#39;; And to retrieve it:
SELECT current_setting(\u0026#39;myschema.id_region\u0026#39;) AS id_region; One can also use a the set_config function in a PL/PgSQL function. The third parameter of set_config specifies if the variable is local to the transaction (true) or global (false).
PERFORM set_config(\u0026#39;myschema.id_region\u0026#39;, \u0026#39;38\u0026#39;, false); To retrieve its value inside a PL/PgSQL block, current_setting can be directly used in assignment or with SELECT ... INTO statement.
a := current_setting(\u0026#39;myschema.id_region\u0026#39;); Please note that you can also, obviously, use a table for this. Some other PL languages, such as PL/Perl, have global variables, and may also be an interesting alternative.
`}),e.add({id:15,href:"/from-oracle-to-postgresql/sequences-migration/",title:"Sequences migration",section:"Porting database objects",content:` Sequences migration # There is little work on sequences. Sequences are very similar in PostgreSQL and Oracle. A few points need attention, though.
On a general basis, clauses preceded by NO to use default values need a space between NO and the rest of the clause to be ported to PostgreSQL. For example, the NOMAXVALUE clause from Oracle has to be translated to NO MAXVALUE for PostgreSQL. However, Oracle\u0026rsquo;s NOCACHE clause has no equivalent in PostgreSQL, but it can be converted to CACHE 1, or simply removed. Only the ORDER and NOORDER have no equivalent in PostgreSQL, as they are a specificity of Oracle RAC.
References:
CREATE SEQUENCE Sequence usage # Sequences aren\u0026rsquo;t use the same way in PostgreSQL and Oracle. Oracle\u0026rsquo;s syntax is sequence_name.operation, while PostgreSQL\u0026rsquo;s syntax is operation('sequence_name').
For instance, the following call, from Oracle:
sequence_name.nextval has to be rewritten to this for PostgreSQL:
nextval(\u0026#39;sequence_name\u0026#39;) References:
CREATE SEQUENCE Sequence Manipulation Functions `}),e.add({id:16,href:"/from-oracle-to-postgresql/contact-us/",title:"Contact us",section:"Docs",content:` Contact us # Dalibo has been providing services, training and support to its clients since 2005. Dalibo offers a wide range of services for PostgreSQL® and its related software. Each mission is focused on 3 main goals: data safety, performance and quality of services.
To assist you in your migration project to PostgreSQL, our sales team will be happy to answer you.
🌐 https://dalibo.com 💌 contact@dalibo.com 🏠 43, rue du Faubourg Montmartre, 75009 Paris 📞 +33 1 83 64 61 88 Postgres, PostgreSQL and the Slonik Logo are trademarks or registered trademarks of the PostgreSQL Community Association of Canada, and used with their permission `}),e.add({id:17,href:"/from-oracle-to-postgresql/cursors/",title:"Cursors",section:"PL/SQL to PL/pgSQL porting",content:` Cursors # The cursors variable\u0026rsquo;s notation is different in Oracle and PostgreSQL.
Cursors declaration # With Oracle, a cursor is declared this way: CURSOR mycursor. This has to be reverted with PostgreSQL: mycursor CURSOR. This is performed by Ora2Pg.
Oracle\u0026rsquo;s REF CURSOR and SYS_REFCURSOR also have to be modified, both to REFCURSOR for PostgreSQL.
Oracle uses the IN keyword to pass parameters to the cursor. This is not necessary with PostgreSQL, it just has to be removed.
The following declaration, with Oracle:
CURSOR command_lines_cursor(cd_num IN VARCHAR2) IS SELECT * FROM command_lines WHERE cd_number = cd_num; should be converted this way:
command_lines_cursor CURSOR (cd_num VARCHAR) FOR SELECT * FROM command_lines WHERE cd_number = cd_num; References:
Record Types Returning a cursor # A function can return a cursor with PostgreSQL, as it does with Oracle. Oracle\u0026rsquo;s return data type is my_table%ROWTYPE, while PostgreSQL\u0026rsquo;s is REFCURSOR.
For instance, with Oracle, returning a cursor will be declared this way:
TYPE return_cur IS REF CURSOR RETURN my_table%ROWTYPE; p_retcur return_cur; Whereas with PostgreSQL, the declaration will be this one:
return_cur REFCURSOR; Cursor exit # The exit code of a cursor loop has to be modified. Oracle\u0026rsquo;s construct EXIT WHEN ...%NOTFOUND is not accepted by PostgreSQL. It has to be replaced by this kind of construct: IF NOT FOUND THEN EXIT; END IF;. The SQL%NOTFOUND also has to be replaced by NOT FOUND. Both these transformations are performed by Ora2Pg.
The following PL/SQL extract:
LOOP FETCH c1 INTO my_ename, my_sal, my_hiredate; EXIT WHEN c1%NOTFOUND; ... END LOOP; will be converted this way:
LOOP FETCH c1 INTO my_ename, my_sal, my_hiredate; IF NOT FOUND THEN EXIT; END IF; ... END LOOP; `}),e.add({id:18,href:"/from-oracle-to-postgresql/index-migration/",title:"Index migration",section:"Porting database objects",content:` Index migration # Only the BTree indexes match between both databases. The other index types from Oracle don\u0026rsquo;t exist in PostgreSQL, but postgreSQL also has some indexes types of its own. Anyway, most indexes are BTree, as its the default type in both databases.
Index on character string # When an index is built to improve searches on the LIKE operator on a string type column, this index has to be built using the varchar_pattern_ops operator class for a varchar column, text_pattern_ops for a text column, or bpchar_pattern_ops for a char column. These operator classes are used when the database\u0026rsquo;s collation isn\u0026rsquo;t C.
The operator class has to be added after the target column name in the index creation statement:
CREATE INDEX emp2_ename ON emp2 (ename varchar_pattern_ops); References:
Operator Classes and Operator Families Bitmap Index # A bitmap index proposed by Oracle is required when a column stored a few distinct values. Bitmap index use a internal array of bits as a physical representation of a value in the table. A simple case is biological gender, encoded in an array of two bits: one for male, another for female. For each row, a bit is adressed in the bitmap index structure. This one provides extrem compactness only if column has a few distinct values.
On-disk bitmap indexes dont exist in PostgreSQL. That can be created in-memory from a BTree index if required. BTree indexes are much larger than On-disk bitmap indexes, but have a much better concurrency. Another technic involves GIN indexes, used by composite data like arrays or hstore columns.
GIN stands for Generalized Inverted Index. Each possible values are referred as keys and rows are stored in their associated key (example gender=F). Each key value is stored only once, so a GIN index is very compact for cases where the same key appears many times.
For a gender column, GIN is constructed over two posting lists (female and male). Following example shows differences between Btree and GIN indexes in their storage:
-- Use btree_gin extension to manipulate scalar columns CREATE extension btree_gin; CREATE TABLE t1 (name VARCHAR, gender CHAR); -- Gender is equally represented INSERT INTO t1 SELECT i, CASE WHEN i%2 = 0 THEN \u0026#39;F\u0026#39; ELSE \u0026#39;M\u0026#39; END FROM generate_series(1,100000000) g(i); CREATE INDEX idx_gender_gin ON t1 USING gin (sexe); SELECT pg_size_pretty(pg_table_size(\u0026#39;t1\u0026#39;)); -- pg_size_pretty -- ---------------- -- 4223 MB SELECT pg_size_pretty(pg_table_size(\u0026#39;idx_gender_gin\u0026#39;)); -- pg_size_pretty -- ---------------- -- 102 MB SELECT pg_size_pretty(pg_table_size(\u0026#39;idx_gender_btree\u0026#39;)); -- pg_size_pretty -- ---------------- -- 2142 MB The large work memory is set to store the whole bitmap in memory. If it had been smaller, the bitmap would have become “lossy”, meaning that it would only hold block numbers, and not records themselves. The sieving through records would have required to visit many more blocks.
GIN provides good compactness and concurrency access and could be used to mimic Bitmap Indexes when column\u0026rsquo;s values are few as possible.
References:
Article by Hans-Juergen Schoenig: GIN – Just A Kind Of Index Reverse index # Reverse indexes make it possible to optimize searchs such as LIKE '%string', which usually don\u0026rsquo;t benefit from an index. There is no reverse index in PostgreSQL, but a trigram index with pg_trgm extension could be used in place.
The trigram indexes can either use GiST or GIN indexing. GiST is faster for Nearest-Neighbor search (called Knn-search in the literature), GIN much faster for strict matching, but requires 3 consecutive characters in the pattern (which is usually a good idea for fast searchs).
They can be used for LIKE '%string', but also for LIKE '%string%', or LIKE '%str%ing%'. GIN indexes are usually a bit bigger and cost more to update than a BTree index.
The pg_trgm extension, though not included in PostgreSQL directly, is distributed along with PostgreSQL (postgresql-contrib package) and maintained by PostgreSQL\u0026rsquo;s developers themselves.
This index type is not directly created by Ora2Pg, it has to be performed manually.
CREATE EXTENSION pg_trgm; CREATE INDEX idx_emp_ename_trgm ON emp USING gist (ename gist_trgm_ops); --or CREATE INDEX idx_emp_ename_trgm ON emp USING gin (ename gin_trgm_ops); The execution plan of a SELET query demonstrates the use of the idx_emp_ename_trgm index:
EXPLAIN SELECT * FROM emp WHERE ename LIKE \u0026#39;%IN%\u0026#39;; -- QUERY PLAN -- ---------------------------------------------------------------------------------------- -- Bitmap Heap Scan on emp (cost=1442.95..3522.23 rows=32742 width=20) -- Recheck Cond: ((ename)::text ~~ \u0026#39;%IN%\u0026#39;::text) -- -\u0026gt; Bitmap Index Scan on idx_emp_ename_trgm (cost=0.00..1434.77 rows=32742 width=0) -- Index Cond: ((ename)::text ~~ \u0026#39;%IN%\u0026#39;::text) These trigram indexes can also be used on case-insensitive matching, using ILIKE.
References:
K-Nearest-Neighbor Indexing, What\u0026rsquo;s new in PostgreSQL 9.1? pg_trgm Non blocking index creation # PostgreSQL can create index without blocking concurrent modifications on the database, using CREATE INDEX CONCURRENTLY. This statement may though leave an index to an invalid state if its creation fails. This can happen if the index cannot be built, for instance a UNIQUE index that cannot be validated.
In a same thought, rebuilding an index without blocking is performed with REINDEX CONCURRENTLY. Like creation process, an index can be left in invalid state.
References:
CREATE INDEX REINDEX `}),e.add({id:19,href:"/from-oracle-to-postgresql/transaction-management/",title:"Transaction management",section:"Porting SQL queries",content:` Transaction management # Transactions and locks are very similar between Oracle and PostgreSQL. There are two major differences. First, Oracle implicitely starts a new transaction when a statement is run and keeps it running until COMMIT, while PostgreSQL is using autocommit by default. A transaction must be explicitely started with BEGIN.
The other difference is the way MVCC is implemented in both databases. PostgreSQL\u0026rsquo;s version has the benefit that a ROLLBACK is instantaneous. In return, the modified blocs of a rollbacked transaction will be physically present in, as PostgreSQL will have created new versions of updated lines, although they have been cancelled. This space will have to be reclaimed afterwards by VACUUM.
The BEGIN statement has several synonyms:
BEGIN; BEGIN WORK; BEGIN TRANSACTION; START TRANSACTION. References:
BEGIN START TRANSACTION Isolation Level # One can specify an isolation level by specifying it in the beginning statement of a transaction:
BEGIN [ WORK | TRANSACTION ] [ mode_transaction [, ...] ] where transaction_mode is:
ISOLATION LEVEL {SERIALIZABLE | REPEATABLE READ | READ COMMITTED | READ UNCOMMITTED } READ WRITE | READ ONLY [ NOT ] DEFERRABLE READ UNCOMMITTED is a synonym of READ COMMITTED under PostgreSQL and Oracle: MVCC engines don\u0026rsquo;t need the READ UNCOMMITTED mode, as writers and readers dont block each other.
Furthermore, Oracle and PostgreSQL both implement the SERIALIZABLE level. PostgreSQL and Oracle implement this level with optimistic locking, in order to improve transactional throughput. Most RDBMS implement this level through pessimistic locking, severely impairing throughput.
With Oracle, one can set the isolation level of all future transactions at the session level. This is done with this statement:
ALTER SESSION SET ISOLATION LEVEL ...; This is done inside a transaction block with PostgreSQL:
BEGIN TRANSACTION ISOLATION LEVEL ...; ... COMMIT; PostgreSQL\u0026rsquo;s way of determining serialization failures is a bit stricter than Oracle\u0026rsquo;s, but the two modes are very similar. For instance, the example given in table 7 of this document \u0026ldquo;On Transaction Isolation Levels\u0026rdquo; generates a serialization error in PostgreSQL, while Oracle doesn\u0026rsquo;t catch it.
create table a ( x int ); create table b ( x int ); Time Session #1 Session #2 t1 ALTER SESSION SET isolation_level=serializable; t2 ALTER SESSION SET isolation_level=serializable; t3 INSERT INTO a SELECT count(*) FROM b; t4 INSERT INTO b SELECT count(*) FROM a; t5 COMMIT; t6 COMMIT; PostgreSQL does not allow session #2 to commit its changes due to snapshot violation. A error message is thrown to user and suggest to retry the complete transaction block to succeed.
ERROR: could not serialize access due to read/write dependencies among transactions DETAIL: Reason code: Canceled on identification as a pivot, during commit attempt. HINT: The transaction might succeed if retried. References:
Transaction Isolation SET TRANSACTION Constraint checking # Integrity constraints are checked on every modification, whether or not it is executed in a transaction. To require compliance with these constraints within a complex transaction, it is possible to defer these verifications at the time of the COMMIT.
Oracle and PostgreSQL provide the same SQL syntax for defining whether a constraint is always deferred:
ALTER TABLE ... CONSTRAINT ... [NOT] DEFERRABLE INITIALLY (IMMEDIATE | DEFERRED) It is also possible to disable checking within an ongoing transaction using the following statement, common to both systems:
SET CONSTRAINT (cons_name | ALL) DEFERRED; Finally, it may be necessary to define at a session level that all future transactions are deferred by default. In this case, the commands between Oracle and PostgreSQL have differences.
With Oracle, the following syntax should be changed from:
ALTER SESSION SET CONSTRAINTS = DEFERRED; ALTER SESSION SET CONSTRAINTS = IMMEDIATE; To:
SET default_transaction_deferrable = ON; SET default_transaction_deferrable = OFF; SET CONSTRAINTS SAVEPOINT # SAVEPOINTS work the same way in Oracle and PostgreSQL. Locks acquired before a SAVEPOINT aren\u0026rsquo;t released if a SAVEPOINT is released by a RELEASE SAVEPOINT or a ROLLBACK TO SAVEPOINT.
PostgreSQL\u0026rsquo;s documentation warns against the modification of lines after a SAVEPOINT has been put if those lines have been locked with a SELECT ... FOR UPDATE before the SAVEPOINT. Indeed, the lock acquired by the SELECT ... FOR UPDATE may be released during the ROLLBACK TO SAVEPOINT. The following sequence of SQL statements should thus be avoided:
BEGIN; SELECT * FROM my_table WHERE key = 1 FOR UPDATE; SAVEPOINT s; UPDATE my_table SET ... WHERE key = 1; ROLLBACK TO SAVEPOINT s; References:
SAVEPOINT RELEASE SAVEPOINT ROLLBACK TO SAVEPOINT Lock management # Although PostgreSQL and Oracle are very similar as far as locking is concerned, some subtle differences have to be taken into account.
References:
Explicit Locking Implicit locking # DML statements acquire implicit locks. The most notable difference between Oracle and PostgreSQL is the SELECT statement: Oracle acquires no lock, while PostgreSQL takes an ACCESS SHARE lock. As a consequence, Oracle doesn\u0026rsquo;t protect readers from operations such as a table drop. A SELECT can be interrupted following a DROP TABLE in another session. PostgreSQL\u0026rsquo;s locking prevents that.
INSERT, UPDATE and DELETE lock the modified lines, in the same way as Oracle: directly in the record, and not in memory.
References:
Dropping a table during SELECT, blog post from Uwe Hesse Explicit locking # SELECT FOR UPDATE
SELECT FOR UPDATE statements may need modification. Oracle\u0026rsquo;s syntax is indeed richer than PostreSQL\u0026rsquo;s as far as this statement is concerned.
Oracle\u0026rsquo;s syntax accepts both WAIT and NOWAIT. PostgreSQL accepts only NOWAIT, WAIT being the default behaviour. SELECT … FOR UPDATE WAIT becomes SELECT … FOR UPDATE.
Oracle\u0026rsquo;s OF clause is incompatible with PostgreSQL\u0026rsquo;s. This is used to specify the table to be locked for the coming update. The difference is the Oracle\u0026rsquo;s OF clause specify a column, while PostgreSQL\u0026rsquo;s specifies a table.
References:
SELECT FOR UPDATE LOCK TABLE
Oracle\u0026rsquo;s LOCK TABLE syntax is compatible with PostgreSQL\u0026rsquo;s in most cases. All of Oracle\u0026rsquo;s locking modes exist in PostgreSQL, and PostgreSQL has a few more of them.
As for the SELECT FOR UPDATE statement, Oracle proposes both WAIT and NOWAIT, while PostgreSQL only has NOWAIT, WAIT being the default.
Oracle\u0026rsquo;s PARTITION and SUBPARTITION clauses cannot be converted though. If the target database also uses partitioning, the child table must be targeted for the locking.
References:
LOCK TABLE `}),e.add({id:20,href:"/from-oracle-to-postgresql/partitioning/",title:"Partitioning",section:"Porting database objects",content:` Partitioning # PostgreSQL accepts declarative partitioning since version 10 and things keep getting better from major release to another. A table is devided into partitions as declared by its partitioned key, which is decisive when defining the model and could be costly to change during the life of the data. Unlike Oracle, the partitioned table must be create separately before the partitions can be defined.
List Partitioning # The following partitioned table for Oracle:
CREATE TABLE t1 (c1 integer, c2 varchar2(100)) PARTITION BY LIST (c1) ( PARTITION t1_a VALUES (1, 2, 3), PARTITION t1_b VALUES (4, 5), PARTITION t1_default VALUES (DEFAULT) ); will be converted to this in PostgreSQL:
CREATE TABLE t1(c1 integer, c2 varchar(100)) PARTITION BY LIST (c1) ; CREATE TABLE t1_a PARTITION OF t1 FOR VALUES IN (1, 2, 3); CREATE TABLE t1_b PARTITION OF t1 FOR VALUES IN (4, 5); CREATE TABLE t1_default PARTITION of t1 DEFAULT; Range Partitioning # Oracle allows range declaration using LESS THAN expression in order to join the lower bound of one partition with the upper bound of another partition. Data values are strictly between -∞ and last defined upper bound.
CREATE TABLE t2 (c1 integer, c2 varchar2(100)) PARTITION BY RANGE (c1) ( PARTITION t2_a VALUES LESS THAN (0), PARTITION t2_b VALUES LESS THAN (100), PARTITION t2_c VALUES LESS THAN (MAXVALUE) ); Each bounds of a partition must be specified when declaring with PostgreSQL, the upper bound is excluded from partition range. The above partitioned table will be converted this way:
CREATE TABLE t2 (c1 integer, c2 varchar(100)) PARTITION BY RANGE (c1); CREATE TABLE t2_a PARTITION OF t2 FOR VALUES FROM (MINVALUE) TO (0); CREATE TABLE t2_b PARTITION OF t2 FOR VALUES FROM (0) TO (100); CREATE TABLE t2_c PARTITION OF t2 FOR VALUES FROM (100) TO (MAXVALUE); Automatic Range Partitioning # Oracle supports automatic partition addition using INTERVAL clause and an interval expression like DAY TO SECOND or YEAR TO MONTH. In example below, only the first partition is needed as a transition point; all data inserted will cause a partition to be created when value is greater that the upper bound of the transition point.
CREATE TABLE t2_auto (c1 number(6), c2 date) PARTITION BY RANGE (c2) INTERVAL (NUMTOYMINTERVAL(1, \u0026#39;MONTH\u0026#39;)) ( PARTITION t2_part VALUES LESS THAN (TO_DATE(\u0026#39;01-JAN-2020\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)) ); INSERT INTO t2_auto VALUES (1, TO_DATE(\u0026#39;01-DEC-2000\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)); INSERT INTO t2_auto VALUES (2, TO_DATE(\u0026#39;01-OCT-2022\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)); INSERT INTO t2_auto VALUES (3, TO_DATE(\u0026#39;01-DEC-2022\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)); The USER_TAB_PARTITIONS view describes table definition, including new partitions with a generated name.
TABLE_NAME PARTITION_NAME HIGH_VALUE T2_AUTO T2_PART TO_DATE(\u0026lsquo;2020-01-01\u0026rsquo;, \u0026lsquo;SYYYY-MM-DD\u0026rsquo;) T2_AUTO SYS_P472681 TO_DATE(\u0026lsquo;2021-11-01\u0026rsquo;, \u0026lsquo;SYYYY-MM-DD\u0026rsquo;) T2_AUTO SYS_P472682 TO_DATE(\u0026lsquo;2023-01-01\u0026rsquo;, \u0026lsquo;SYYYY-MM-DD\u0026rsquo;) This automatique partition management feature is not available natively with PostgreSQL. However, it is possible to mimic the behaviour presented above using the pg_partman project. This extension relies on configuration tables and a maintenance routine to detect partitioned tables requiring new partitions.
Unlike Oracle, a new row outside one of existing bound is inserted into default partition. The maintenance routine takes care of moving rows asynchronously according to their values in a new partition.
Here an example with the previous table t2_auto, which can be managed by pg_partman. The premake option allows to prepare n partitions from the interval next to the time of the function call.
CREATE TABLE t2_auto (c1 integer, c2 date) PARTITION BY RANGE (c2); CREATE SCHEMA partman; CREATE EXTENSION pg_partman WITH SCHEMA partman; SELECT partman.create_parent( p_parent_table =\u0026gt; \u0026#39;public.t2_auto\u0026#39;, p_control =\u0026gt; \u0026#39;c2\u0026#39;, p_type =\u0026gt; \u0026#39;native\u0026#39;, p_interval =\u0026gt; \u0026#39;monthly\u0026#39;, p_premake =\u0026gt; 1 ); The following query show the distribution of three rows in existing partitions:
INSERT INTO t2_auto VALUES (1, \u0026#39;2000-12-01\u0026#39;); INSERT INTO t2_auto VALUES (2, \u0026#39;2022-10-01\u0026#39;); INSERT INTO t2_auto VALUES (3, \u0026#39;2022-12-01\u0026#39;); SELECT tableoid::regclass, * from t2_auto; -- tableoid | c1 | c2 -- -----------------+----+------------ -- t2_auto_p2022_10 | 2 | 2022-10-01 -- t2_auto_default | 1 | 2000-12-01 -- t2_auto_default | 3 | 2022-12-01 pg_partman offers a series of maintenance functions to add new partitions and spread rows from the default partitions to more relevant partitions. These operations must be scheduled by an external orchestrator (cron, pg_cron_, etc.) or using the background process provided by the extension. This last solution requires setting the pg_parman_bgw value to the shared_preload_libraries parameter and restarting the instance.
-- Monitor for data getting inserted into parent/default tables SELECT * FROM partman.check_default(); -- Move data from these parent/default tables into the proper children SELECT * FROM partman.partition_data_time(p_parent_table =\u0026gt; \u0026#39;public.t2_auto\u0026#39;); -- Automatically create child tables for partition sets configured to use it. CALL partman.run_maintenance_proc(); The data is now in the correct partitions.
SELECT tableoid::regclass, * from t2_auto; -- tableoid | c1 | c2 -- -----------------+----+------------ -- t2_auto_p2000_12 | 1 | 2000-12-01 -- t2_auto_p2022_10 | 2 | 2022-10-01 -- t2_auto_p2022_12 | 3 | 2022-12-01 Hash Partitioning # To evenly distribute the data between a finite number of partitions, Oracle and PostgreSQL offer the same hash partitioning operation.
The following partitioned table with Oracle:
CREATE TABLE t3 (c1 integer, c2 varchar2(100)) PARTITION BY HASH (c1) ( PARTITION t3_a, PARTITION t3_b, PARTITION t3_c ); Will be converted with PostgreSQL like this:
CREATE TABLE t3 (c1 integer, c2 varchar(100)) PARTITION BY HASH (c1); CREATE TABLE t3_a PARTITION OF t3 FOR VALUES WITH (modulus 3, remainder 0); CREATE TABLE t3_b PARTITION OF t3 FOR VALUES WITH (modulus 3, remainder 1); CREATE TABLE t3_c PARTITION OF t3 FOR VALUES WITH (modulus 3, remainder 2); When a new partition need to be added, especially to redistribute rows in a larger number of partitions, Oracle chooses a partition according to its hashing algorithm to divide the content in two parts and redistributes one of the halves into the new partition.
With Oracle, the following instruction performs operations transparently:
ALTER TABLE t3 ADD PARTITION t3_d; With PostgreSQL, it is up to the administrator to select the source partition by expanding the modulus and remainder options to split the two (or more) subsets of data, each half will be moved into a new partition. This operation requires getting a lock through a transaction while copying data to the two new partitions:
BEGIN; -- Replacement of a partition by two subsets ALTER TABLE t3 DETACH PARTITION t3_c; CREATE TABLE t3_c_0 PARTITION OF t3 FOR VALUES WITH (modulus 6, remainder 0); CREATE TABLE t3_c_3 PARTITION OF t3 FOR VALUES WITH (modulus 6, remainder 3); -- Move lines INSERT INTO t3 SELECT * FROM t3_c; DROP TABLE t3_c; COMMIT; Composite Partitioning # All previous methods can be mixed to meet more precise partitioning needs, on several levels of partitioned keys. Consider the following table with Oracle has a high level of list partitioning and a low level of range partitioning, also known as as composition partitioning or subpartitioning:
CREATE TABLE t4 (c1 char(1), c2 date) PARTITION BY LIST (c1) SUBPARTITION BY RANGE (c2) ( PARTITION t4_a VALUES (\u0026#39;A\u0026#39;) ( SUBPARTITION t4_a_2020 VALUES LESS THAN (TO_DATE(\u0026#39;01-JAN-2021\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)), SUBPARTITION t4_a_2021 VALUES LESS THAN (TO_DATE(\u0026#39;01-JAN-2022\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)), SUBPARTITION t4_a_2022 VALUES LESS THAN (TO_DATE(\u0026#39;01-JAN-2023\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)) ), PARTITION t4_b VALUES (\u0026#39;B\u0026#39;) ( SUBPARTITION t4_b_2020 VALUES LESS THAN (TO_DATE(\u0026#39;01-JAN-2021\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)), SUBPARTITION t4_b_2021 VALUES LESS THAN (TO_DATE(\u0026#39;01-JAN-2022\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)), SUBPARTITION t4_b_2022 VALUES LESS THAN (TO_DATE(\u0026#39;01-JAN-2023\u0026#39;,\u0026#39;dd-MON-yyyy\u0026#39;)) ) ); With PostgreSQL, it is possible to attach partitioned tables to another partition table. Partitions define the final depth level. The previous example will be rewritten like this:
CREATE TABLE t4 (c1 char(1), c2 date) PARTITION BY LIST (c1); CREATE TABLE t4_a PARTITION OF t4 FOR VALUES IN (\u0026#39;A\u0026#39;) PARTITION BY RANGE (c2); CREATE TABLE t4_a_2020 PARTITION OF t4_a FOR VALUES FROM (MINVALUE) TO (\u0026#39;2021-01-01\u0026#39;); CREATE TABLE t4_a_2021 PARTITION OF t4_a FOR VALUES FROM (\u0026#39;2021-01-01\u0026#39;) TO (\u0026#39;2022-01-01\u0026#39;); CREATE TABLE t4_a_2022 PARTITION OF t4_a FOR VALUES FROM (\u0026#39;2022-01-01\u0026#39;) TO (\u0026#39;2023-01-01\u0026#39;); CREATE TABLE t4_b PARTITION OF t4 FOR VALUES IN (\u0026#39;B\u0026#39;) PARTITION BY RANGE (c2); CREATE TABLE t4_b_2020 PARTITION OF t4_b FOR VALUES FROM (MINVALUE) TO (\u0026#39;2021-01-01\u0026#39;); CREATE TABLE t4_b_2021 PARTITION OF t4_b FOR VALUES FROM (\u0026#39;2021-01-01\u0026#39;) TO (\u0026#39;2022-01-01\u0026#39;); CREATE TABLE t4_b_2022 PARTITION OF t4_b FOR VALUES FROM (\u0026#39;2022-01-01\u0026#39;) TO (\u0026#39;2023-01-01\u0026#39;); Partitioning is usually used for several purposes. The first one is performance. If the partitioning is adequate and the queries correctly written in order to take advantage of partitioning, then PostgreSQL will limit reads to only the tables holding the candidate data, and not all partitions.
Another use case partitioning can fulfill is maintenance. Partitioning can ease management of historical data. For example, if partitioning per year, when one wants to get rid of data from a certain year, one should simply drop the partition containing obsolete data. Furthermore, maintenance operations (VACUUM, ANALYZE) will be easier.
However, declarative partitioning in PostgreSQL may have some shortcomings compared to Oracle functionnalities. For example, foreign key constraints defined with ON DELETE ... CASCADE can have surprising behaviors on partitioned tables before version 15, when moving a row between two partitions triggers the unwanted deletion of foreign key related rows.
References :
Table Partitioning Partitioning use cases with PostgreSQL Projet pg_partman Release 15: Enforce foreign key correctly during cross-partition updates `}),e.add({id:21,href:"/from-oracle-to-postgresql/pl-sql-specificities/",title:"PL/SQL specificities",section:"PL/SQL to PL/pgSQL porting",content:` PL/SQL specificities # Autonomous transactions # We often find PRAGMA associated with autonomous transactions in PL/SQL. This last notion does not exist in PostgreSQL.
It is possible to emulate autonomous transactions through a dblink, but it is a particularly counter-efficient solution that consumes resources. Indeed, the use of a dblink will cause a new database connection. The cost of a new connection is significant and a additional connection will require to properly size the max_connections parameter and will consume additional memory and CPU time.
The following Oracle PL/SQL code shows the declaration of a procedure with AUTONOMOUS_TRANSACTION pragma:
CREATE PROCEDURE LOG_ACTION (username VARCHAR2, msg VARCHAR2) IS PRAGMA AUTONOMOUS_TRANSACTION; BEGIN INSERT INTO table_tracking VALUES (username, msg); COMMIT; END log_action; A possible rewrite with a dblink involves filling in the information to connect to the local PostgreSQL instance:
CREATE EXTENSION dblink; CREATE OR REPLACE FUNCTION log_action(username TEXT, msg TEXT) RETURNS void AS $$ BEGIN perform dblink_connect(\u0026#39;pragma\u0026#39;, format( \u0026#39;dbname=%s user=test password=test\u0026#39;, current_database() )); perform dblink_exec(\u0026#39;pragma\u0026#39;, format( \u0026#39;insert into table_tracking values (%s, %s);\u0026#39;, username, msg )); perform dblink_exec(\u0026#39;pragma\u0026#39;,\u0026#39;commit;\u0026#39;); perform dblink_disconnect(\u0026#39;pragma\u0026#39;); END; $$ LANGUAGE plpgsql; Another alternative, which appeared in version 9.5 with background workers, is to rely on the extension pg_background to deport the execution of a procedure to a new transaction using of a wrapper procedure and the pg_background_launch method of the extension.
Another rewrite of the previous code would look like this with pg_background, with the creation of a calling procedure:
-- Create the function we will be \u0026#34;remotely\u0026#34; calling: CREATE OR REPLACE FUNCTION log_action_atx(username TEXT, msg TEXT) RETURNS void AS $$ BEGIN INSERT INTO table_tracking VALUES (username, msg); END; $$ LANGUAGE plpgsql; -- Now we can write the calling function CREATE OR REPLACE FUNCTION log_action(username TEXT, msg TEXT) RETURNS void AS $$ DECLARE v_query text; BEGIN v_query := format( \u0026#39;SELECT true FROM log_action_atx (%s, %s)\u0026#39;, quote_nullable(username), quote_nullable(msg) ); PERFORM pg_background_result( pg_background_launch(v_query) ); END; $body$ LANGUAGE plpgsql SECURITY DEFINER; The log_action method behaves exactly as if it were executing a statement in a autonomous transaction.
References:
Autonomous transaction support in PostgreSQL VARRAY collections # VARRAY collections in Oracle packages are migrated to PostgreSQL arrays. Their definition is created by Ora2Pg, but they usually need a rewrite of the code using them.
When a VARRAY is a simple array of a scalar datatype, there is less rewriting work to be done than when dealing with a %ROWTYPE VARRAY. In this case, there is quite a lot of work.
The following code:
DECLARE TYPE Calendar IS VARRAY(366) OF DATE; will be converted to:
CREATE TYPE calendar AS (date[366]); The next one, though converted by Ora2Pg, won\u0026rsquo;t work without modification:
TYPE t_tab_emp IS VARRAY (1000) OF emp%ROWTYPE; ... tab_emp t_tab_emp; Associative arrays and nested tables # TABLE OF collections are usually used to declare functions returning a set of records. As a consequence, the TABLE OF types can be replaced by a RETURNS TABLE or a RETURNS SETOF data_type for simple data types. Please refer to PIPELINED attribute and PIPE ROW instruction for an example where a TABLE OF collection is not necessary.
Anyway, Ora2Pg translates this data type to an array of the associated type, and will probably need some rework of the translated code.
Thus, the following declaration:
CREATE TYPE information IS TABLE OF VARCHAR2(255); will be converted to an array of varchar(255) by Ora2Pg:
CREATE TYPE information AS VARCHAR(255)[]; The NUMBER INDEX clause has no equivalent, though. For instance, the following declaration:
TYPE t_list_qlf_id IS TABLE OF NUMBER INDEX BY VARCHAR2(5); cannot be directly converted. One can use the hstore contrib module, or the JSONB datatype, to emulate this feature.
References:
hstore `}),e.add({id:22,href:"/from-oracle-to-postgresql/oracles-packages/",title:"Oracle's packages",section:"PL/SQL to PL/pgSQL porting",content:" Oracle\u0026rsquo;s packages # Proprietary packages have few or no equivalents in PostgreSQL. It is possible rewrite them entirely or to rely on free contributions to obtain behavior close to those proposed by Oracle.\nDBMS_OUTPUT package calls # Calls to Oracle\u0026rsquo;s DBMS_OUTPUT.put_line, DBMS_OUTPUT.put and DBMS_OUTPUT.new_line output functions are replaced to RAISE NOTICE by Ora2Pg.\nThus, the following procedure, from Oracle:\nCREATE PROCEDURE allAuthors IS TYPE my_array IS varray(100) OF VARCHAR(25); temp_arr my_array; BEGIN ... DBMS_OUTPUT.put_line(i || \u0026#39;) name: \u0026#39; || temp_arr..(i)); ... END allAuthors; will be translated like this for PostgreSQL:\nCREATE FUNCTION allAuthors() RETURNS VOID AS $$ DECLARE temp_arr VARCHAR(25)[]; BEGIN ... RAISE NOTICE \u0026#39;% ) name: %\u0026#39;, i, temp_arr..(i); ... END; $$ LANGUAGE plpgsql; DBMS_XXX package calls # Some are implemented in the Orafce library, as:\nUTL_FILE DBMS_PIPE DBMS_OUTPUT DBMS_ALERT Some advanced features of these Oracle modules can also be integrated into non-PostgreSQL tools or extensions:\nOracle Advanced Queuing =\u0026gt; see PgQ Oracle Jobs scheduler =\u0026gt; see pgAgent / pg_timetable / pg_cron And some others can very easily be written with a language extended procedural like Perl. For example, if you were using the UTL_SMTP module to send emails from your database, the following code will very simply do the same thing:\nCREATE OR REPLACE FUNCTION send_email(name, INET, TEXT, TEXT, TEXT) RETURNS INTEGER AS $body$ use Net::SMTP; my ($Db, $Ip, $sendTo, $Subject, $Message) = @_; my $smtp = Net::SMTP-\u0026gt;new(\u0026#34;mailhost\u0026#34;, Timeout =\u0026gt; 60); $smtp-\u0026gt;mail(\u0026#34;$Db\\@$Ip\u0026#34;); $smtp-\u0026gt;recipient($sendTo); $smtp-\u0026gt;data(); $smtp-\u0026gt;datasend(\u0026#34;To: $sendTo\\n\u0026#34;); $smtp-\u0026gt;datasend(\u0026#34;Subject: $Subject\\n\u0026#34;); $smtp-\u0026gt;datasend(\u0026#34;Content-Type: text/plain;\\n\\n\u0026#34;); $smtp-\u0026gt;datasend(\u0026#34;$Message\\n\u0026#34;); $smtp-\u0026gt;dataend(); $smtp-\u0026gt;quit(); return 1; $body$ language \u0026#39;plperlu\u0026#39;; SELECT send_email( current_database(), inet_server_addr(), \u0026#39;dba@dom.com\u0026#39;, \u0026#39;test pg_utl_smtp\u0026#39;, \u0026#39;Just a test\u0026#39; ); References:\nPGQ Tutorial "})})()